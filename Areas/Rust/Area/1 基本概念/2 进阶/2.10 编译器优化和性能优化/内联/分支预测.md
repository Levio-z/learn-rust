内联 → 条件融合 → 分支预测优化 → CPU乱序执行配合
### 1. 内联后的“融合性” —— 条件表达式的合成优化
```rust
if once.is_completed() {
    return *cached.get();
}

```
如果 `is_completed()` 没有被内联，编译器和 CPU 看不清里面的逻辑，它变成：
```rust
call once::is_completed
test eax, eax
jne return_cached

```
但如果你用了 `#[inline]`，它展开后等价于：
```rust
if once.state_and_queued.load(Ordering::Acquire) == COMPLETE {
    return *cached.get();
}

```
编译器可以将其优化为：
```rust
mov rax, [state_ptr]
cmp rax, COMPLETE
je  fast_path

```
这里的**“条件融合”**就是：编译器将你的布尔判断 + 原子 load 合并成一次 CPU 比较指令，不再涉及函数调用、寄存器回传等“逻辑碎片”。
### 2. 更有利于[编译原理-分支预测-基本概念](../../../../../../basic/编译原理/分支预测/编译原理-分支预测-基本概念.md) —— 条件越清晰，越容易预测
现代 CPU 的 **分支预测器（branch predictor）**工作原理是：
- 记录过去相同分支条件的结果（是/否）；
- 根据统计信息猜测下一次会怎么走；
- 如果猜对：执行连续；
- 如果猜错：CPU流水线全部清空，**代价非常大（几百个周期）**。

💡当 `if condition()` 是一个函数调用时，预测器只能靠**函数调用点**来建模型；
💡但如果 `if some_atomic_value == constant`，CPU 就能构造**指令级预测模型**，精度高、开销低。
### 3. 更适配 CPU 的乱序执行引擎
CPU 乱序执行的核心逻辑：
- **能并行的指令就并行**；
- **依赖清晰的数据流关系**可重排；
- 对于函数调用：是一个“黑盒”，有副作用，不乱序；
- 对于原子指令和条件比较：可分析，可调度。
    

✅ 内联后，整个 fast path 逻辑变成几个原子指令 + 条件跳转，不再有不可预测的调用行为，因此 CPU 的乱序引擎就能大胆调度，比如：
```rust
mov rax, [state_ptr]         ; (1) Load
cmp rax, COMPLETE            ; (2) Compare
je  .return_cached           ; (3) Branch

```
这一整套指令可以和其他 load/store 并行穿插执行，提高**执行吞吐率（IPC）**。
### 总结
内联使得 fast path 的判断逻辑变成透明的原子 load + 条件跳转组合，编译器能融合表达式，CPU 能更精确预测，乱序引擎能并行调度，从而显著提升性能。