我们通过分析3个复杂性越来越高的发生拥塞的情况，开始对拥塞控制的一般性研究。在每种情况下，我们首先将看看出现拥塞的原因以及拥塞的代价(根据资源未被充分利用以及端系统得到的低劣服务性能来评价)。我们暂不关注如何对拥塞做出反应或避免拥塞，而是重点理解一个较为简单的问题，即随着主机增加其发送速率并使网络变得拥塞，这时会发生的情况。

### 1.情况1:两个发送方和一台具有无穷大缓存的路由器
![](Pasted%20image%2020250618173053.png)图3-43 拥塞情况1:两条连接共享具有无限大缓存的单跳路由

我们假设主机A中的应用程序以λ字节/秒的平均速率将数据发送到连接中(例如，通过一个套接字将数据传递给运输层协议)。这些数据是初始数据，这意味着每个数据单元仅向套接字中发送一次。下面的运输层协议是一个简单的协议。数据被封装并发送;不执行差错恢复(如重传)、流量控制或拥塞控制。忽略由于添加运输层和较低层首部信息产生的额外开销，在第一种情况下，主机A向路由器提供流量的速率是λ字节/秒。主机B也以同样的方式运行，为了简化问题，我们假设它也是以速率λ字节/秒发送数据。来自主机A和主机B的分组通过一台路由器，在一段容量为R的共享式输出链路上传输。该路由器带有缓存，可用于当分组到达速率超过该输出链路的容量时存储“人分组”​。在此第一种情况下，我们将假设路由器有无限大的缓存空间。

图3-44描绘出了第一种情况下主机A的连接性能。左边的图形描绘了**每连接的吞吐量(per-connection throughput)(接收方每秒接收的字节数)与该连接发送速率之间的函数关系**。当发送速率在0~R/2之间时，接收方的吞吐量等于发送方的发送速率，即发送方发送的所有数据经有限时延后到达接收方。然而当发送速率超过R/2时，它的吞吐量只能达R/2。这个吞吐量上限是由两条连接之间共享链路容量造成的。链路完全不能以超过R/2的稳定状态速率向接收方交付分组。无论主机A和主机B将其发送速率设置为多高，它们都不会看到超过R/2的吞吐量。
![](Pasted%20image%2020250618173359.png)取得每连接R/2的吞吐量实际上看起来可能是件好事，因为在将分组交付到目的地的过程中链路被充分利用了。**但是，图3-44b的图形却显示了以接近链路容量的速率运行时产生的后果。当发送速率接近R/2时(从左至右)，平均时延就会越来越大。当发送速率超过R/2时，路由器中的平均排队分组数就会无限增长**，源与目的地之间的平均时延也会变成无穷大(假设这些连接以此发送速率运行无限长时间并且有无限量的缓存可用)。**因此，虽然从吞吐量角度看，运行在总吞吐量接近R的状态也许是一个理想状态，但从时延角度看，却远不是一个理想状态。甚至在这种(极端)理想化的情况中，我们已经发现了拥塞网络的一种代价，即当分组的到达速率接近链路容量时，分组经历巨大的排队时延**。

### 2.情况2:两个发送方和一台具有有限缓存的路由器
现在我们从下列两个方面对情况1稍微做一些修改(参见图 3-45)。首先，假定路由器缓存的容量是有限的。这种现实世界的假设的结果是，**当分组到达一个已满的缓存时会被丢弃**。其次，**我们假定每条连接都是可靠的。如果一个包含有运输层报文段的分组在路由器中被丢弃，那么它终将被发送方重传。由于分组可以被重传，所以我们现在必须更小心地使用发送速率这个术语**。特别是我们再次以_字节/秒表示应用程序将初始数据发送到套接字中的速率。运输层向网络中发送报文段(含有初始数据或重传数据)的速率用字/秒表示。有时被称为网络的供给载荷(offered load)。
![](Pasted%20image%2020250618173555.png)
图3-45 情况2:(有重传的)两台主机与一台拥有有限缓存的路由器在情况2下实现的性能强烈地依赖于重传的方式。首先，考虑一种不真实的情况，即主机A能够以某种方式(不可思议地!)确定路由器中的缓存是否空闲，因而仅当缓存空闲时才发送一个分组。在这种情况下，将不会产生丢包，入与入’相等，并且连接的吞吐量就等于入…。图3-46a中描述了这种情况。从吞吐量的角度看，性能是理想的，即发送的每个分组都被接收到。注意到在这种情况下，平均主机发送速率不能超过R/2，因为假定不会发生分组丢失。

接下来考虑一种更为真实的情况，**发送方仅当在确定了一个分组已经丢失时才重传**。
(同样，所做的假设有一些弹性。然而，**发送主机有可能将超时时间设置得足够长，以无形中使其确信一个还没有被确认的分组已经丢失**。 
- 即使某个分组还**没有被确认**（ACK 没到），如果超时时间已经到了，发送方也会**认为它“丢失了”**。
在这种情况下，性能就可能与图 3-46b所示的情况相似。为了理解这时发生的情况，考虑一下供给载荷入(初始数据传输加上重传的总速率)等于R/2 的情况。根据图3-46b，在这一供给载荷值时，数据被交付给接收方应用程序的速率是R/3。因此，在所发送的0.5R 单位数据当中，从平均的角度说，0.333R字节/秒是初始数据，而0.166R字节/秒是重传数据。我们在此看到了另一种网络拥塞的代价，即发送方必须执行重传以补偿因为缓存溢出而丢弃（丢失）的分组。
最后，我们考虑一种情况：**发送方可能会提前发生超时并重传在队列中已被推迟但还未丢失的分组**。在这种情况下，初始数据分组和重传分组都可能到达接收方。接收方只需要一份这样的分组副本，重传分组将被丢弃。在这种情况下，路由器转发重传的初始分组副本是在做无用功，因为接收方已收到了该分组的初始版本。而路由器本可以利用链路的传输能力去发送另一个分组。这里，我们又看到了网络拥塞的另一种代价，即发送方在遇到大时延时所进行的不必要重传会引起路由器利用其链路带宽来转发不必要的分组副本。图 3-46c 显示了当假定每个分组被路由器转发（平均）两次时，吞吐量与供给载荷的对比情况。由于每个分组被转发两次，当其供给载荷接近 R/2 时，其吞吐量将渐近 R/4。
-  TCP 设置了重传超时时间 RTO；
	- 如果 RTT 波动大或网络临时拥堵，ACK 到达会**延迟**；
	- 此时，**发送方可能误以为丢包并重传原始分组**；
	- 实际上，初始分组还在路上，并**最终成功送达接收方**；
	- 那么：**重传是“冗余”的，路由器浪费了资源。**
- 路由器不知道分组是否是冗余的；
	- 一旦收到来自发送方的数据，它就会**照样排队、转发**；
	- 但这可能意味着：
	    - 本来能转发有意义的分组（未曾到达的分组）
	    - 却被用去转发无意义的重传副本（接收方早已收到了原始分组）

![](Pasted%20image%2020250618195910.png)

### 3. 情况3:4 个发送方和具有有限缓存的多台路由器及多跳路径
在最后一种拥塞情况中，有4台主机发送分组，每台都通过交叠的两跳路径传输，如图 3-47 所示。我们再次假设每台主机都采用超时/重传机制来实现可靠数据传输服务，所有的主机都有相同的入..值，所有路由器的链路容量都是R字节/秒。
我们考虑从主机A到主机C的连接。该连接经过路由器R1和R2。A-C连接与D-B连接共享路由器R1，并与B-D连接共享路由器R2。对极小的入值，路由器缓存的溢出是很少见的(与拥塞情况1、拥塞情况2中的一样)，吞吐量大致接近供给载荷。对稍大的入值，对应的吞吐量也更大，因为有更多的初始数据被发送到网络中并交付到目的地，溢出仍然很少。因此，对于较小的入_的增大会导致入。.的增大。
![](Pasted%20image%2020250618200735.png)
>我们考虑从主机 A 到主机 C 的连接。该连接经过路由器 R1 和 R2。A-C 连接与 D-B 连接共享路由器 R1，并与 B-D 连接共享路由器 R2。

这构建了一个**多路径交叠的场景**：
- A → C 的路径是：`A → R1 → R2 → C`
- D → B 的路径是：`D → R1 → A`（也用到了 R1）
- B → D 的路径是：`B → R2 → D`（也用到了 R2）    
所以：
- R1 是 A-C 与 D-B 的**共享路由器**；
- R2 是 A-C 与 B-D 的**共享路由器**。
这意味着，**A-C 的链路会与其他连接产生资源竞争**。

>对极小的入值，路由器缓存的溢出是很少见的，吞吐量大致接近供给载荷。

`入值`（offered load）即主机**试图发送的数据速率**。
当所有主机都很“温和”地发送数据（例如每秒几十 KB），则：
- 路由器处理能力绰绰有余；
- 缓冲队列不会溢出；
- 没有丢包，也没有重传；
- 所以：**吞吐量 ≈ 供给负载**，即「你发多少就收到多少」。

>在负载较小或中等时，主机增加发送速率（供给负载），网络吞吐量也随之线性或次线性地增加。
- 网络负载提升，但路由器还能应付；
- 数据仍然大多能成功送达；
- 因此：
    - 虽然发得更多，但收的也更多；
    - **吞吐量随着供给载荷一起增长**。
在考虑了流量很小的情况后，下面分析当 λin′​（因此 λin′​）很大时的情况。考虑路由器 R2。不管 λin′​ 的值是多大，到达路由器 R2 的 A-C 流量（在经过路由器 R1 转发后到达路由器 R2）的到达速率至多是 R，也就是从 R1 到 R2 的链路容量。如果 λin′​ 对于所有连接（包括 B-D 连接）来说是极大的值，那么在 R2 上，B-D 流量的到达速率可能会比 A-C 流量的到达速率大得多。因为 A-C 流量与 B-D 流量在路由器 R2 上必须为有限缓存空间而竞争，所以当来自 B-D 连接的供给载荷越来越大时，A-C 连接上成功通过 R2（即由于缓存溢出而未被丢失）的流量会越来越小。在极限情况下，当**供给载荷趋近于无穷大时，R2 的空闲缓存会立即被 B-D 连接的分组占满，因而 A-C 连接在 R2 上的吞吐量趋近于 0**。这又一次说明在重载的极限情况下，A-C 端到端吞吐量将趋近于 0。这些考虑引发了供给载荷与吞吐量之间的权衡，如图 3-48 所示。

当考虑由网络所做的浪费掉的工作量时，随着供给载荷的增加而使吞吐量最终减少的原因是明显的。在上面提到的大流量的情况下，**每当有一个分组在第二跳路由器上被丢弃时，第一跳路由器所做的将分组转发到第二跳路由器的工作就是“劳而无功”的**。如果第一跳路由器只是丢弃该分组并保持空闲，则网络中的情况是幸运的（更准确地说是糟糕的）。需要指出的是，**第一跳路由器所使用的将分组转发到第二跳路由器的传输容量用来传送不同的分组可能更有效益**。(例如，当选择一个分组发送时，路由器最好优先考虑那些已经历过一定数量的上游路由器的分组。)所以，我们在此又看到了由于拥塞而丢弃分组的另一种代价，即**当一个分组沿一条路径被丢弃时，每个上游路由器用于转发该分组到丢弃该分组而使用的传输容量最终被浪费掉了**。


