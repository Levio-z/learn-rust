### 4.1 相似度检索 (Similarity Search)

常用的相似度度量：余弦相似度、向量距离 (欧几里得距离) 等。

ChromaDB 支持多种相似度计算方法:

1. Cosine Similarity (余弦相似度)
    
    - 计算两个向量夹角的余弦值
    - 值域范围为 `[-1,1]`，越接近 1 表示越相似
    - 不受向量长度影响，只关注方向
    - 计算公式: cos(θ) = (A·B)/(||A||·||B||)
2. L2 Distance (欧氏距离)
    
    - 计算两个向量间的直线距离
    - 值越小表示越相似
    - 受向量长度影响
    - 计算公式: d = √(Σ(ai-bi)²)
3. IP (Inner Product, 内积)
    
    - 两个向量对应位置相乘后求和
    - 值越大表示越相似
    - 受向量长度影响
    - 计算公式: IP = Σ(ai×bi)

ChromaDB 默认使用 Cosine Similarity，这也是最常用的相似度计算方法，因为:

- 计算简单高效
- 不受向量绝对大小影响
- 对于文本语义相似度计算效果好
- 结果容易解释和标准化

在实际使用中，可以根据具体场景选择合适的相似度算法:

- 如果向量已归一化，三种方法等价
- 对向量长度敏感时选择 Cosine
- 关注绝对距离时选择 L2
- 需要快速计算时可用 IP

### 4.2 重排序 (Re-ranking) 重要吗？

重排序是一个重要的步骤，可以显著提升检索结果的质量。其工作原理如下：

1. 初步检索
    
    - 首先使用向量相似度搜索召回一批候选文档(如前20-100条)
    - 这一步计算快速但可能不够精确
2. Cross-Encoder 重排序
    
    - 对召回的候选文档进行更精细的相关性打分
    - Cross-Encoder 会同时看到 query 和文档内容，计算它们的匹配度
    - 相比向量相似度，能更好地理解语义关联
    - 但计算开销较大，所以只用于重排少量候选
3. 应用场景
    
    - 多路召回：不同检索方式召回的结果需要统一排序
    - 高精度要求：需要更准确的相关性排序
    - 复杂查询：简单向量相似度可能不足以理解查询意图
4. 常见实现
    
    - 使用预训练的 Cross-Encoder 模型(如 BERT)
    - 可以针对具体任务进行微调
    - 输出相关性分数用于重新排序

虽然重排序会增加一定延迟，但在对准确度要求较高的场景下，这个成本通常是值得的。

### 4.3 拼接上下文与用户问题

在检索到相关文档片段后，需要将它们与用户问题拼接成合适的 prompt，以供 LLM 生成回答。

用户问题 + 检索到的上下文 = Prompt，最终由 LLM 输出回答。

以下是一些常见的拼接策略：

1. 基本结构
    
    - System: 系统指令，说明 AI 助手的角色和任务
    - Context: 检索到的相关文档片段
    - Human: 用户的实际问题
    - Assistant: AI 的回答
2. 拼接技巧
    

我们在项目中做了一个有意思的事情，就是可以使用 `[[citation:1]]` 这样的格式来引用检索到的上下文。

然后用户可以在前端通过 Markdown 的格式来展示引用信息, 并且通过弹窗来展示引用详情。
![](asserts/Pasted%20image%2020250728092326.png)
在 RAG Web UI 中， 我们使用 LangChain 的模板来实现这个功能：

可查阅： `backend/app/services/chat_service.py`
```
from langchain.prompts import PromptTemplate qa_system_prompt = ( "You are given a user question, and please write clean, concise and accurate answer to the question. " "You will be given a set of related contexts to the question, which are numbered sequentially starting from 1. " "Each context has an implicit reference number based on its position in the array (first context is 1, second is 2, etc.). " "Please use these contexts and cite them using the format [citation:x] at the end of each sentence where applicable. " "Your answer must be correct, accurate and written by an expert using an unbiased and professional tone. " "Please limit to 1024 tokens. Do not give any information that is not related to the question, and do not repeat. " "Say 'information is missing on' followed by the related topic, if the given context do not provide sufficient information. " "If a sentence draws from multiple contexts, please list all applicable citations, like [citation:1][citation:2]. " "Other than code and specific names and citations, your answer must be written in the same language as the question. " "Be concise.\n\nContext: {context}\n\n" "Remember: Cite contexts by their position number (1 for first context, 2 for second, etc.) and don't blindly " "repeat the contexts verbatim." )
```
