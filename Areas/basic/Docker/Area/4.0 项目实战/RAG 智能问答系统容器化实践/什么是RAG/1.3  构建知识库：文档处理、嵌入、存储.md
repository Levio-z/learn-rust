### 3.1 文档上传与分块 (Chunking)

#### 3.1.1 为什么要对文档进行分块？

文档分块是 RAG 系统中的一个关键步骤，主要有以下几个原因：

1. 向量相似度计算的精度
    
    - 过长的文本会导致向量表示不够精确
    - 较小的文本块能更好地捕捉局部语义
    - 有助于提高检索的准确性
2. LLM 的上下文窗口限制
    
    - LLM 的输入长度是有限的 （虽然 Qwen 已经推出了 1M token 的上下文窗口 0.0）
    - 需要将文档切分为适合 LLM 处理的大小
    - 避免超出 token 限制导致信息丢失
3. 检索效率与成本
    
    - 更小的文本块便于建立细粒度的索引
    - 只需检索最相关的片段，节省 token 用量
    - 减少无关信息，提高回答质量
4. 引用与溯源 （这个是 RAG 的特色功能）
    
    - 便于定位信息的具体来源
    - 可以给出更精确的引用范围
    - 有助于用户验证答案的可靠性

#### 3.1.2 常见的分块策略

1. 固定长度分块
    
    - 按字符数或 token 数进行切分
    - 实现简单，但可能切断语义完整的段落
    - 适合结构统一的文档
2. 语义分块
    
    - 按段落、章节等自然语义单位切分
    - 保持上下文的连贯性
    - 需要考虑文档的具体结构
3. 重叠分块
    
    - 相邻块之间保留一定重叠
    - 避免关键信息被切分
    - 增加了存储和计算开销
4. 递归分块
    
    - 先大块后细分
    - 保持层次结构
    - 适合长文档处理

选择合适的分块策略需要考虑：

- 文档的类型和结构
- 向量数据库的特性
- LLM 的上下文窗口大小
- 检索效率与成本的平衡

例如如果是 markdown，可以按段落进行分块，如果是一般文档，可以按章节进行分块。

```
+--------------------------------------------------+

| # Chapter 1 Title |

| Main content... |

| Main content... |

| |

| ## 1.1 Section Title |

| - List item 1 |

| - List item 2 |

| |

| ### 1.1.1 Subsection Title |

| Main paragraph... |

| |

| # Chapter 2 Title |

| Another paragraph... |

+--------------------------------------------------+

|

v

Chunking 切片

|

v

+------------------+ +-------------------+ +------------------+

| Chunk 1: | | Chunk 2: | | Chunk 3: |

| # Chapter 1 | | ## 1.1 Section | | # Chapter 2 |

| Title | | Title | | Title |

| Main content... | | - List item 1 | | Another |

| Main content... | | - List item 2 | | paragraph... |

+------------------+ | | +------------------+

| ### 1.1.1 |

| Subsection Title |

| Main paragraph... |

+-------------------+
```

### 3.2 文本向量化 (Embedding)

文本向量化是将自然语言文本转换为高维向量空间中的数值向量的过程。这种转换使得我们可以：

- 用数学方法计算文本之间的语义相似度
- 在向量空间中进行高效的相似度搜索
- 保留文本的语义信息和上下文关系

常用的文本向量化模型包括：

1. OpenAI Embeddings
    
    - text-embedding-ada-002 模型
    - 1536 维向量输出
    - 适用于英文等多种语言
    - 语义表达能力强
2. Sentence Transformers
    
    - 开源的句子级别编码器
    - 支持多语言
    - 可以根据场景微调
    - 计算效率高

在 RAG Web UI 中，主要是用的 OpenAI 的 text-embedding-ada-002 模型。

```
from langchain_openai import OpenAIEmbeddings

...

embeddings = OpenAIEmbeddings(

openai_api_key=settings.OPENAI_API_KEY,

openai_api_base=settings.OPENAI_API_BASE

)
```

### 3.3 向量数据库

在文本 Embedding 之后，需要将向量存储到向量数据库中，以便后续的检索和相似度计算。

在 RAG Web UI 中，主要是用的 ChromaDB 作为向量数据库， 同时支持使用 Factory 模式， 支持多种向量数据库，例如：

1. ChromaDB
2. Qdrant
3. Milvus
4. Faiss
5. Annoy
6. Pinecone
7. Zilliz

向量数据库除了存储向量，还要携带某些元信息(文档来源、段落位置等)方便查阅， 一般情况下，我们会存入这样的数据结构到向量数据库中：

除了向量之外， 我们还需要存入一些元数据， 例如：

`{     
	"id": "chunk_id",     
	"text": "段落内容",     
	"metadata": {"source": "文档来源", "position": "段落位置", "hash": "段落哈希值"} 
}`
