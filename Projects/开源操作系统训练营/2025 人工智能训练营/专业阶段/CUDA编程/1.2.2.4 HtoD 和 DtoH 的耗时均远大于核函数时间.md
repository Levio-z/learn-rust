![](asserts/Pasted%20image%2020250812150817.png)

![](asserts/Pasted%20image%2020250812150847.png)

![](asserts/Pasted%20image%2020250812150831.png)


![](asserts/Pasted%20image%2020250812150915.png)

- https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf

- GPU内存带宽


### 内存墙
◆ 摩尔定律：算力每18-24个月翻倍 
◆ 但 DRAM 每年 +~10% 
◆ 冯·诺依曼架构: **数据必须在处理器和内存之间频繁传输** 
◆ 数据量大或计算密度低时 → 内存瓶颈 
◆ 总结：处理器（CPU/GPU）计算速度远快于 内存访问速度！

![](asserts/Pasted%20image%2020250812151432.png)
https://arxiv.org/pdf/2403.14123

观察： 
◆ 19.5 TFLOPS = 𝟏. 𝟗𝟓 × 𝟏𝟎𝟏𝟑 𝒐𝒑/𝒔𝒆𝒄 
◆ 2039 GB/s = 𝟐. 𝟎𝟑𝟗 × 𝟏𝟎𝟏𝟐 𝒃𝒚𝒕𝒆𝒔/𝒔𝒆𝒄 
◆ 即便 80GB HBM2e，速度相对算力有限 
◆ 对于 float 加法而言： 
	◆ 12 bytes 内存访问（2读+1写） 
	◆ 1 op 
◆ → **本身需要的内存访问较多，而计算量很少**

◆ 重要发现：理论上加法的性能瓶颈在内存访问上 
◆ 如何直观快速的判断一个算子在某个硬件上的性能瓶颈？ 
◆ 如何量化性能瓶颈？
→ 有助于判断和优化

### Roofline模型
![](asserts/Pasted%20image%2020250812151909.png)

![](asserts/Pasted%20image%2020250812152011.png)
β最大内存带宽
I 最大计算强度

特性： 
◆ 硬件有影响——Hardware-dependent 

◆ 拐点：也叫脊点（ridge point），可达到该硬 件理论最高性能的最低计算强度 


◆ 脊点以左：访存密集型，瓶颈在访存 
◆ 脊点以右：计算密集型，瓶颈在计算

示例： 
◆ Float 加法: 1 𝐹𝐿𝑂𝑃 /12 𝑏𝑦𝑡𝑒𝑠 = 1 /12 ≈ 𝟎. 𝟎𝟖𝟑 𝑭𝑳𝑶𝑷 𝒃𝒚𝒕𝒆 
◆ A100： 
◆ 19.5 TFLOPS = 𝟏. 𝟗𝟓 × 𝟏𝟎𝟏𝟑 𝒐𝒑/𝒔𝒆𝒄 
◆ 2039 GB/s = 𝟐. 𝟎𝟑𝟗 × 𝟏𝟎𝟏𝟐 𝒃𝒚𝒕𝒆𝒔/𝒔𝒆𝒄 
◆ 𝐼𝑚𝑎𝑥 = 𝟏.𝟗𝟓×𝟏𝟎𝟏𝟑 𝑭𝑳𝑶𝑷/𝒔𝒆𝒄 𝟐.𝟎𝟑𝟗×𝟏𝟎𝟏𝟐 𝒃𝒚𝒕𝒆𝒔/s𝒆𝒄 ≈ 𝟗. 𝟓𝟔 𝑭𝑳𝑶𝑷 𝒃𝒚𝒕𝒆 

◆ 确实是访存密集型
◆ 加法是比较典型的访存密集型算子 
### 优化访存密集型很重要
◆ 计算密集型？→ GEMM，之后… 
◆ **访存密集型算子占大多数**，因为 
	◆ 内存墙 ：内存硬件和计算机架构导致算子很容易受到内存影响
	◆ 深度学习等领域数据量大 
◆ 因此，**优化访存密集型算子**很重要！ 

◆ 刚才的 Roofline 分析提供**理论基础**，实际情况更为复杂，实际达到的性能还取决于其他因 素…（e.g., 代码实现）
- 算子本身不够效率
- 时钟频率？


### Nsight Compute
使用完整路径名
```
 sudo /usr/local/cuda/bin/ncu --print-details all --nvtx --call-stack --set full ./target/add_gpu02
```
[3 修改性能计数器权限](chatgpt/3%20修改性能计数器权限.md)
- WSL2 支持 GPU 加速（NVIDIA CUDA），但很多硬件层面的调试和性能分析功能受限。
- Nsight Compute 在 WSL 里只能做最基本的分析，不能访问底层硬件计数器。
- 这就是你看到 `ERR_NVGPUCTRPERM` 的根本原因，无法解决。

◆ 想分析之前的 GPU 并行加法代码 
◆ → Nsight Compute (ncu) ：英伟达的内核级性能分析工具 
◆ 使用 ncu CLI ：
```
sudo ncu --print-details --nvtx --call-stack --set full ./add_cuda
```
◆ 导出文件并使用 ncu GUI：
```
sudo ${ncu} --nvtx --call-stack --set full -f --export add_cuda.ncu-rep ./add_cuda
```


![](asserts/Pasted%20image%2020250812160203.png)

每个核函数一行 
包含函数名、GPU 运行时间、计算吞吐%、内存吞吐% 等信息
%达到最大性能的多少
![](asserts/Pasted%20image%2020250812160227.png)

Details → GPU Speed Of Light Throughput

基础强度0.12

![](asserts/Pasted%20image%2020250812160624.png)

观察： 
◆ 内存吞吐利用率比计算高不少 → 访存密集型 
◆ ncu 会根据测量的指标给出建议

加法的性能瓶颈在内存访问上 
◆ 因此想办法：提升其访存效率 观察： 
◆ 内存使用率虽相对较高，但仍有较大提升空间 
◆ 要增大内存带宽使用，如果一次多传输数据呢？…

### 向量化

◆ 标量操作 → 向量操作 
◆ 向量化（vectorization）：一次同时操作多个标量数据 解决之前的问题： 
◆ 一次多传输数据：向量化访存，即一次同时传输（读写） 多个标量数据 → 提升访存效率
◆ 向量化本质是 SIMD (Single Instruction Multiple Data) 
◆ SIMD: 同时对一组 (向量) 数据中的每一个分别执行相同的操作从而 实现空间上的并行
### SIMT vs SIMD
![](asserts/Pasted%20image%2020250812161157.png)

### 如何向量化
◆ 想进行向量化访存，怎么操作呢？
◆ 多种方式，其中最简单的一种：内置向量化访存类型 
	◆ float2, float3, float4 …
![](asserts/Pasted%20image%2020250812161316.png)

![](asserts/Pasted%20image%2020250812161322.png)
float4 的内部实现

https://docs.nvidia.com/cuda/cuda-c-programming-guide/#built-in-vector-types

### 示例：向量化访存加法

复制add_gpu02创建新文件add_gpu03，做以下修改
```c++
// 设备端模板加法函数，支持标量和 CUDA 向量类型

template <typename T>

__device__ T add(const T &a, const T &b)

{

    if constexpr (std::is_arithmetic_v<T>) {

        // 标量类型（如 float、int 等）直接相加

        return a + b;

    }

    else if constexpr (std::is_same_v<T, float2>) {

        // CUDA 内置二维向量逐分量相加

        return make_float2(a.x + b.x, a.y + b.y);

    }

    else if constexpr (std::is_same_v<T, float4>) {

        // CUDA 内置四维向量逐分量相加

        return make_float4(a.x + b.x, a.y + b.y, a.z + b.z, a.w + b.w);

    }

    else {

        // 不支持的类型触发编译错误

        static_assert(sizeof(T) == 0, "Unsupported type for add()");

    }

}
```
核函数
```c++
// Kernel

template<typename T>

__global__ void add_kernel(T *c, const T *a, const T *b, size_t n, size_t step) {

    int idx = blockIdx.x * blockDim.x + threadIdx.x+step;

    for(size_t i =idx;i<n;i+=step){

        c[i] = add(a[i],b[i]);

    }

}
```
◆ 和之前一样的核函数和外层调用函数 （template！） 
◆ 使用一个模板 add() 函数来封装不同类 型的加法操作 
◆ __device__: 表示这是个仅在 GPU 上 运行的函数 
◆ make_float2, make_float4: float2 和 float4 的创建函数

测试
```
nvcc add_gpu/add_gpu03.cu -o target/add_gpu03
```
[5 特化版本](chatgpt/5%20特化版本.md)

![](asserts/Pasted%20image%2020250812162825.png)

![](asserts/Pasted%20image%2020250812163132.png)
◆ float->float2->float4 计算强度不变，性能提升 → 符合逻辑 ◆ float3 左移了一点，为什么呢？

观察： float->float2->float4 
◆ Memory% 上升但 Compute% 下降 → 访存密集型特征 
◆ 向量化访存倍数增加，Memory% 增加 → 符合逻辑

![](asserts/Pasted%20image%2020250812164336.png)
◆ float2 为什么比 float4 快一点？结论 恒定吗？ 
答案： ◆ 并不是！
◆ 数据量x16，float4 最快了 
疑问： 
◆ 那一直提升向量化倍数能继续提高吗？

### 向量化倍数可以一直提高

![](asserts/Pasted%20image%2020250812164514.png)

观察： 
◆ 增加向量化倍数 → 增加使用的 register 数量 
◆ 但 register 数量有限，超出时会资源紧张/竞争，造成 寄存器溢出（register spilling） 
◆ Register → Local memory，访问延时增加
![](asserts/Pasted%20image%2020250812164636.png)

◆ 但 float3 怎么比 float 还慢…? ◆ ncu 看看！
![](asserts/Pasted%20image%2020250812164740.png)
![](asserts/Pasted%20image%2020250812164756.png)

观察： 
◆ float、float2、float4 ALU（基础计算）的使用均高于 LSU(数据读写)，但 float3 反常明显高于 ALU 位居第一 
◆ …什么意思？
意思是 float3 反常的有更多的读写操作！

◆ 那…为什么呢？
### 内存对齐
◆ GPU 全局内存 (DRAM) 访问以内存事务 (transaction) 为单位（总线宽度决定） 
- → 即便只需1字节数据，也必须搬运整个数据块 
◆ DRAM 的基础事务单位是 32 bytes，缓存行 128 bytes 
◆ 内存对齐：事务的起始地址需是 32 的整数倍 
◆ 如果没有对齐会怎么样？
![](asserts/Pasted%20image%2020250812165233.png)
没办法在一次取出来，时间翻倍

### 内存合并
◆ **CUDA 线程调度的最小单位为 线程束 (warp) (不是每个线程单独调度哦）** 
	→ CUDA 一个 warp 是 32 个线程 
◆ 什么意思？意思就是同一个周期内，一个 warp 中的线程统一执行同一条指令 
◆ 内存合并 (Memory Coalescing)：将同一 warp 的多个内存访问合并为少数事务，最大化内 存带宽利用率

![](asserts/Pasted%20image%2020250812165417.png)