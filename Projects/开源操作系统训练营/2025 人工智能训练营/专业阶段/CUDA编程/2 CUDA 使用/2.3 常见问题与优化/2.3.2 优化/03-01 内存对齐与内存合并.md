# GPU 内存访问优化核心：内存对齐 & 内存合并
---
## 1\. 内存对齐（Memory Alignment）
-   **硬件层面限制**  
    GPU 访问全局内存（DRAM）是以**固定大小事务（transaction）为单位**的，典型大小是 32 bytes。
-   **对齐要求**  
    内存访问的起始地址必须是事务大小的整数倍（32 bytes 的整数倍），否则访问会跨多个事务，导致多次加载。
-   **后果**
    -   如果不对齐（比如访问的起始地址是 30），数据会跨越两个事务边界
    -   **需要发起两次内存事务，延迟和带宽成本翻倍**
-   **缓存行**
    -   GPU L2 缓存行大小通常为 128 bytes
    -   L1 和 L2 缓存对齐同样要求，未对齐访问会增加缓存访问复杂度
---
## 2\. 内存合并（Memory Coalescing）
-   **线程束（Warp）和执行模型**
    -   CUDA 的最小调度单位是一个 warp，包含 32 个线程
    -   warp 内所有线程在同一时钟周期执行同一条指令
-   **内存访问特点**
    -   warp 中各线程若访问的地址是**连续且对齐的内存区域**，GPU 可以将这些访问合并为**少数几个内存事务**
    -   这称为“内存合并”，能极大提升内存带宽利用率，减少访存延迟
-   **要求**
    -   **连续访问**：warp 内线程访问的地址应连续（例如线程 i 访问数组的第 i 个元素）
    -   **对齐要求**：访问起始地址必须满足硬件的对齐要求（32 bytes 整数倍）
    -   **限定 warp 范围**：只有同一个 warp 内线程的访问才能合并
---
## 3\. 为什么内存合并这么重要？
-   **减少内存事务次数**
    -   从理论上看，warp 中每个线程访问一个字节数据，如果连续且对齐，理论上只发起一次 32 bytes 的事务
    -   如果不连续或未对齐，事务次数增加，内存带宽浪费严重，性能急剧下降
-   **带宽利用率**
    -   有效利用带宽，是GPU高性能计算的关键
    -   内存合并可显著提升访存带宽利用率，从而提高整体吞吐量
---
## 4\. 形象类比
-   内存事务类似于搬运箱子，大小固定（32 bytes）
-   内存对齐就像你必须从箱子边缘拿货，不能从箱子中间切割拿
-   warp 内线程访问连续数据就像同一批工人协作一起搬一整箱货，减少搬运次数
-   不对齐或访问不连续就像工人分散去不同箱子拿货，效率低且费时
---
## 5\. 实战提示
-   **设计数据结构时优先保证内存对齐和连续**，尽量避免跨事务边界访问
-   **让 warp 线程访问连续内存**（比如按照线程 id 访问数组下标）
-   使用 CUDA 的内存访问分析工具（Nsight Compute）验证是否发生内存合并
---