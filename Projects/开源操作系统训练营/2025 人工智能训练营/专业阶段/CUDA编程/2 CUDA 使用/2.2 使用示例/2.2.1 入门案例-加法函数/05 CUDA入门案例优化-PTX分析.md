### 向量化访存性能提高

◆ 使用向量化访存确实会提升原本访存受限的并行加法性能 
◆ 分析出来的数据证明了这一点，但… 
◆ 有没有更直接的方法能看出向量化访存提升性能的原理呢？ 
◆ 当然有！

### 前情回顾：编译流程
◆ 设备端编译流程中间每个**虚拟架构**会编 译出一个 .ptx 的文件 
◆ 这里面包含着该文件对该虚拟架构的 PTX (Parallel Thread Execution) 代码 
◆ 是一种低级的并行线程执行的虚拟指令 集（ISA）
![](asserts/Pasted%20image%2020250812201436.png)

- https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/#compilation-phases

### 向量化访存-浅看PTX

![](asserts/Pasted%20image%2020250812201812.png)

◆ 6 个 fp32 load 
◆ 3 个 fp32 add 
◆ 3 个 fp32 store 
◆ **float3 没能合并访存 → 单纯 3 个 float**

### 性能能否进一步提升？
![](asserts/Pasted%20image%2020250812202018.png)
◆ 横轴右移 → 提高 计算强度AI 
（1）增加计算量 WWW
- 通过**算子融合**、**重复计算**、**算法改造**，在每次访存数据上做更多运算
- 例：卷积神经网络中融合多个算子减少中间存储，或在矩阵乘法中复用加载的块数据多次计算
- 优点：提高了计算密度
- 缺点：可能增加计算资源占用，需权衡性能与能耗
（2）减少访存量 QQQ
- 通过**压缩数据格式**、**缓存优化**、**减少不必要的数据传输**降低内存访问次数
	- 例：使用半精度浮点数（FP16）代替单精度，减少传输字节数
- 优点：降低访存压力，提高带宽利用率
- 缺点：可能带来精度损失，或需要硬件支持

（3）同时提高 WWW 和降低 QQQ
- 综合利用算子融合和数据压缩、缓存优化等手段，双管齐下最大化 AI
- 这是最理想的提升策略