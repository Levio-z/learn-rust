数据大小：const size_t SIZE = 1 << 24; // 元素总数 half个数
```
nvcc add_gpu/add_gpu04_half2.cu -o target/add_gpu04_half2
```

```
nsys profile -t cuda,nvtx,osrt -o target/add_gpu04 -f true target/add_gpu04_half2
```

```
nsys stats target/add_gpu04.nsys-rep
```

```
./target/add_gpu04
```

```
 ** CUDA API Summary (cuda_api_sum):

 Time (%)  Total Time (ns)  Num Calls   Avg (ns)    Med (ns)   Min (ns)  Max (ns)   StdDev (ns)           Name         
 --------  ---------------  ---------  -----------  ---------  --------  ---------  -----------  ----------------------
     95.1        503800539          3  167933513.0   478474.0    464162  502857903  290053030.2  cudaMalloc            
      3.8         20105170          4    5026292.5  4582150.0   3841348    7099522    1532111.4  cudaMemcpy            
      0.8          4231753          1    4231753.0  4231753.0   4231753    4231753          0.0  cuLibraryLoadData     
      0.2          1193864          3     397954.7   319446.0    314521     559897     140267.8  cudaFree              
      0.1           600487          1     600487.0   600487.0    600487     600487          0.0  cudaLaunchKernel      
      0.0             1669          1       1669.0     1669.0      1669       1669          0.0  cuModuleGetLoadingMode
      0.0              970          1        970.0      970.0       970        970          0.0  cuLibraryGetKernel    
      0.0              746          1        746.0      746.0       746        746          0.0  cuKernelGetName         

```

### 半精度并行加法

◆ 和之前一样的核函数、外层调用函数 和封装的 add() 函数（template！） 
◆ half2: CUDA 支持的内置半精度类型 
◆ 用 float 之类的也可以

![](asserts/Pasted%20image%2020250812203326.png)

half2的PTX
![](asserts/Pasted%20image%2020250812203351.png)
◆ 好像有点复杂 
◆ 不过因为我们把 half2 的每部分都拆开来对位计算，**载入**没有存回的向量化程度 
◆ 而且用了两个加法指令 
◆ 有没有办法优化？

### 向量化计算
![](asserts/Pasted%20image%2020250812203622.png)


![](asserts/Pasted%20image%2020250812203711.png)

![](asserts/Pasted%20image%2020250812203726.png)


![](asserts/Pasted%20image%2020250812203747.png)



float → half 增幅大的原因： 
◆ AI 右移给出更多性能提升空间 
◆ 移动的幅度理论上是翻倍 → 提升不小 
◆ 回忆：Roofline 是跟硬件相关的！ 
	→ 天花板会变！FP16 比 FP32 的算力更高！ 
◆ Roofline 中的 kernel point 大概率同时还会上移！ （i.e., 右上移动相对于原 FP32，而非仅仅右移）

![](asserts/Pasted%20image%2020250812203923.png)


![](asserts/Pasted%20image%2020250812204015.png)
