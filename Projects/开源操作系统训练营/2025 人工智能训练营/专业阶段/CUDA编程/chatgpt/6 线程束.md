### 1\. **CUDA 线程调度的最小单位是 Warp**

-   在 CUDA 架构中，**线程调度的基本单位不是单个线程，而是一个 Warp（线程束）**。
    
-   **一个 Warp 固定由 32 个连续编号的线程组成**，这些线程被硬件同时调度和执行。
    
-   同一个 Warp 内的所有线程在同一时钟周期内**必须执行同一条指令（SIMT，单指令多线程）**，但每个线程可使用不同的寄存器数据。
    
-   这种设计兼顾了 SIMD 的并行性和线程灵活性，是 CUDA 高效执行的核心。
    

---

### 2\. **Warp 同步执行同一条指令的含义**

-   同一 Warp 的 32 个线程共同执行程序计数器（PC）指向的同一条指令。
    
-   如果有条件分支导致线程行为分歧，Warp 会分成多个子 Warp 交替执行，称为 Warp 分支分裂（warp divergence），会带来性能损失。
    
-   因此，**写出分支一致的代码对提升 CUDA 性能非常关键**。
    

---

### 3\. **内存合并 (Memory Coalescing) 的作用**

-   Warp 中多个线程访问的内存地址如果是连续且对齐的，GPU 会将这些访问合并成少量、甚至一次的全局内存事务（transaction）。
    
-   **内存合并极大提升全局内存带宽利用率，降低访问延迟**，是高效 CUDA 编程的重要原则之一。
    
-   反之，不连续或非对齐的访问会产生大量小事务，导致带宽浪费和性能下降。
    

---

### 总结

| 术语 | 说明 |
| --- | --- |
| Warp | 32 个 CUDA 线程的执行单元，统一调度和指令执行 |
| SIMT | 单指令多线程架构，Warp 内线程同时执行相同指令 |
| Warp Divergence | Warp 内线程分支不一致时执行效率下降 |
| 内存合并 | Warp 中线程的内存访问合并成少量访问事务，提升带宽利用率 |

---