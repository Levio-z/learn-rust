### 总结
- 优化核函数调用次数
	- 外部循环放到内部循环
- HtoD 和 DtoH 的耗时均远大于核函数时间

### 优化核函数
◆运行无误搞定！但是…
◆具体有多少提升呢？比 CPU 循环版本快了多少呢？ 
◆CPU 上计时测试一下<<<1,1>>>, <<<256,256>>> 和满载的情况 
◆在外面循环保证所有数据都被计算

### 修改原文件并创建新文件add_gpu01.cu
主要修改部分
```c++
// Kernel

template<typename T>

__global__ void add_kernel(T *c, const T *a, const T *b, size_t n, size_t step) {

    int idx = blockIdx.x * blockDim.x + threadIdx.x+step;

    if (idx < n) {

        c[idx] = a[idx] + b[idx];

    }

}

  

template<typename T>

void vector_add(T* c,const T *a, const T *b, size_t n,const dim3& grid,const dim3& block){

    size_t step = grid.x * block.x;

    for(size_t i =0;i<n;i+=step){

        add_kernel<T><<<grid,block>>>(c,a,b,n,i);

    }

}
```
调用部分修改
```c++
vector_add( d_c,d_a, d_b,SIZE,grid_dim,block_dim);
```
编译运行
```
nvcc add_gpu/add_gpu01.cu -o target/add_gpu01
```

修改以下内容测试测试一下<<<1,1>>>, <<<256,256>>> 和满载的情况
```
    dim3 block_dim(256);
    dim3 grid_dim(256);
```

### 测试结果
![](asserts/Pasted%20image%2020250812142354.png)

### Nsight Systems（CLI）
>英伟达的系统级性能分析工具

启动profile
```
nsys profile -t cuda,nvtx,osrt -o target/add_cuda -f true target/add_cuda01
```
解析并统计性能信息
```
nsys stats target/add_cuda.nsys-rep
```

![](asserts/Pasted%20image%2020250812143138.png)
rtx5060实际测试
256，256：
cudaMalloc 占时间最多
```
 ** CUDA API Summary (cuda_api_sum):

 Time (%)  Total Time (ns)  Num Calls   Avg (ns)   Med (ns)   Min (ns)  Max (ns)   StdDev (ns)           Name         
 --------  ---------------  ---------  ----------  ---------  --------  ---------  -----------  ----------------------
     96.0        196847281          3  65615760.3   510354.0    466268  195870659  112804053.4  cudaMalloc            
      1.8          3713937          4    928484.3   931930.0    644279    1205798     274335.0  cudaMemcpy            
      1.2          2554358          1   2554358.0  2554358.0   2554358    2554358          0.0  cuLibraryLoadData     
      0.5          1028082         16     64255.1     9205.5      6389     887452     219527.8  cudaLaunchKernel      
      0.5           992131          3    330710.3   277755.0    267844     446532     100426.8  cudaFree              
      0.0             3187         16       199.2       95.5        88        995        234.7  cuKernelGetName       
      0.0             1229          1      1229.0     1229.0      1229       1229          0.0  cuLibraryGetKernel    
      0.0              772          1       772.0      772.0       772        772          0.0  cuModuleGetLoadingMode
```
1，1
cudaLaunchKernel占时间最多
```
 ** CUDA API Summary (cuda_api_sum):

 Time (%)  Total Time (ns)  Num Calls   Avg (ns)   Med (ns)   Min (ns)  Max (ns)   StdDev (ns)           Name         
 --------  ---------------  ---------  ----------  ---------  --------  ---------  -----------  ----------------------
     96.6       7820082096    1048576      7457.8     3191.0      2018    6679537      91181.1  cudaLaunchKernel      
      2.7        218200391          3  72733463.7   496794.0    462281  217241316  125147472.4  cudaMalloc            
      0.6         48613773    1048576        46.4       38.0        32    1921024       1900.6  cuKernelGetName       
      0.1          7256763          4   1814190.8  1607557.0    524106    3517543    1516062.7  cudaMemcpy            
      0.0          2540122          1   2540122.0  2540122.0   2540122    2540122          0.0  cuLibraryLoadData     
      0.0          1049373          3    349791.0   292270.0    218992     538111     167154.8  cudaFree              
      0.0             1466          1      1466.0     1466.0      1466       1466          0.0  cuLibraryGetKernel    
      0.0             1187          1      1187.0     1187.0      1187       1187          0.0  cuModuleGetLoadingMode
```


### 核函数调用有开销，在外面多次循环调用开销巨大
解决方案？→ 循环放在核函数里（Grid-strided loop)
1，1
```
 ** CUDA API Summary (cuda_api_sum):

 Time (%)  Total Time (ns)  Num Calls   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)           Name         
 --------  ---------------  ---------  -----------  -----------  ---------  ---------  -----------  ----------------------
     46.7        228786381          1  228786381.0  228786381.0  228786381  228786381          0.0  cuLibraryLoadData     
     41.8        205160715          3   68386905.0     557815.0     499543  204103357  117533898.8  cudaMalloc            
     10.9         53585604          4   13396401.0     911002.0     572603   51190997   25198065.4  cudaMemcpy            
      0.3          1483351          1    1483351.0    1483351.0    1483351    1483351          0.0  cudaLaunchKernel      
      0.3          1367397          3     455799.0     375415.0     291234     700748     216267.5  cudaFree              
      0.0             1586          1       1586.0       1586.0       1586       1586          0.0  cuModuleGetLoadingMode
      0.0             1092          1       1092.0       1092.0       1092       1092          0.0  cuLibraryGetKernel    
      0.0              793          1        793.0        793.0        793        793          0.0  cuKernelGetName     
```
256
```
 ** CUDA API Summary (cuda_api_sum):

 Time (%)  Total Time (ns)  Num Calls   Avg (ns)   Med (ns)  Min (ns)  Max (ns)   StdDev (ns)           Name         
 --------  ---------------  ---------  ----------  --------  --------  ---------  -----------  ----------------------
     95.8        138549583          3  46183194.3  320233.0    256248  137973102   79492398.3  cudaMalloc            
      3.1          4413043          4   1103260.8  452342.5    399600    3108758    1337443.0  cudaMemcpy            
      0.7           952406          1    952406.0  952406.0    952406     952406          0.0  cuLibraryLoadData     
      0.3           474325          3    158108.3  147377.0    133762     193186      31131.6  cudaFree              
      0.2           295570          1    295570.0  295570.0    295570     295570          0.0  cudaLaunchKernel      
      0.0             1371          1      1371.0    1371.0      1371       1371          0.0  cuModuleGetLoadingMode
      0.0              798          1       798.0     798.0       798        798          0.0  cuLibraryGetKernel    
      0.0              643          1       643.0     643.0       643        643          0.0  cuKernelGetName       

```
![](asserts/Pasted%20image%2020250812142354.png)
修改后：
![](asserts/Pasted%20image%2020250812144534.png)

指标：加速比 = 𝑻𝒄𝒑𝒖/ 𝑻𝒈𝒑𝒖 
◆ <<<1,1>>>: ~0.117 
◆ <<<256，256>>>: ~1185.88 
◆ 满载: ~1350.81

为什么？
单GPU每个线程比cpu单个核能力要弱
### HtoD 和 DtoH 的耗时均远大于核函数时间 

![](asserts/Pasted%20image%2020250812144951.png)

观察： 
◆ HtoD 和 DtoH 的耗时均远大于核函数时间 

指标：总耗时 = 𝑻𝑯𝟐𝑫 + 𝑻𝒌𝒆𝒓𝒏𝒆𝒍 + 𝑻𝑫𝟐𝑯

疑问：有消减 H<->D 时间的方法吗？什么时候需要优化？

