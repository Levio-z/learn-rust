![](asserts/Pasted%20image%2020250819154432.png)


![](asserts/Pasted%20image%2020250819155706.png)


### 传统编译器
传统编译器通常划分为三个部分：前端（frontend）、优化器（optimizer）和后端（backend）。编译过程以高级语言 作为输入，前端主要是负责解析源代码的词法和语法分析，检查语法错误，并将源代码转换为中间表示。优化器则是在前端 的基础上，对中间代码进行优化，使得代码更加高效。后端负责将已经优化的中间代码转换为针对硬件平台的机器代码。
IR（Intermediate Representation）：中间表示，用于表示中间代码的数据结构，**IR既是连接前端和后端的桥梁，又是 前端和后端解耦合的工具**，优化器的转换和优化都是围绕IR实现的。

![](asserts/Pasted%20image%2020250819160403.png)
### AI编译器
![](asserts/Pasted%20image%2020250819160524.png)

缺乏对特定计算的优化，缺乏异构编程，无法适配训练和推理的需求（无法针对训练和推理优化）

### AI编译器
AI 编译器是一种针对 AI 和机器学习应用特别优化的编译器，它能够满足推理场景和训练场景不同需求， 将高级语言编写的程序或者训练好的模型文件转换成可以在特定硬件上高效执行的程序。 

1）以 Python 语言为前端
2）拥有多层 IR 设计 （图编译IR、算子编译IR）
3）面向神经网络深度优化 
4）针对不同芯片架构设计 

AI编译器目标： 
◆ 性能优化：极致降低训练、推理耗时，提升吞吐量。 
◆ 资源利用：最大化硬件资源利用率（CPU/GPU/NPU），实现最优能效比。 
◆ 模型压缩：压缩模型体积与计算量，适配移动端/嵌入式设备资源限制。 
◆ 硬件兼容性：生成跨平台可执行代码，覆盖异构硬件架构（x86/ARM/NPU）。 
◆ 梯度计算：自动生成高效反向传播代码，支持动态计算图微分。 
◆ 并行计算：实施数据/模型/流水线并行策略，充分利用多设备算力。

### 传统编译器和AI编译器
![](asserts/Pasted%20image%2020250819160959.png)

#### 前端

![](asserts/Pasted%20image%2020250819161503.png)
前端：计算图经过多种优化， 如代数简化、操作融合、操作下沉、 公共子表达式消除（CSE）、死代码 消除（DCE）和静态内存规划等，得 到初步优化的计算图；随后通过模式 匹配和图重写等方法进一步优化，最 终生成优化后的计算图；

#### 后端
后端：是AI编译器与硬件交互 的关键部分，它负责将优化后的中间 表示转换为特定硬件平台（如CPU、 GPU或TPU）的高效代码。后端模 块通常包括硬件特定的优化器，例如 针对GPU的并行化策略、针对TPU 的矩阵乘法优化，以及针对FPGA的 流水线调度。此外，后端模块还可能 集成自动调优技术，通过搜索算法找 到最优的硬件参数配置，以最大化性 能
![](asserts/Pasted%20image%2020250819161545.png)

### 主流的AI编译器-TVM
![](asserts/Pasted%20image%2020250819161811.png)
① 从 TensorFlow、PyTorch 或 ONNX 等框架导入模型。
② 翻译成 TVM 的高级模型语言 Relay。 
③ 将Relay表示降级为TE表示。 
④ 使用 auto-tuning 模块 AutoTVM 或 AutoScheduler 搜索最佳 schedule。
- 搜索最佳的调度方式
⑤ 为模型编译选择最佳配置（计算+调度）。
⑥ 降级为张量中间表示（TIR，TVM 的底层中间表示）。 
⑦ 编译成机器码。
### 主流的AI编译器——MLIR

MLIR（Multi-Level Intermediate Representa tion）是一种高度模块化的编译器基础设施，专门设 计用于解决异构计算和领域特定编译的挑战。其核心 思想是通过分层中间表示（IR）和可扩展的方言（Di alect）系统，统一不同抽象级别的计算表达，从而 连接高级框架（如TensorFlow/PyTorch）与底层硬 件（如CPU/GPU/TPU）。
![](asserts/Pasted%20image%2020250819162314.png)
- 张量
- 缓冲区
	- 多个变量指向一个内存

![](asserts/Pasted%20image%2020250819162731.png)
竖向，功能与定位

- payload：计算内容，不关心算什么
- Structure：怎么计算，不关心计算内容


### AI程序基本概念-张量
深度神经网络的数据实际上是高度同质，高度非结构化的，**张量就是对这种非结构化数据的一种有效的表示。 张量是动态的高维数组在深度神经网络程序中的别名**。

![](asserts/Pasted%20image%2020250819163040.png)

>指的是把自然语言、关键词、语法现象等语义层面的信息，动态地转化为计算机可以理解和处理的数据。
>这里强调了“动态化”，说明这种映射不是固定死的，而是可以根据上下文、输入语境灵活变化。
#### 张量定义
![](asserts/Pasted%20image%2020250819163530.png)

![](asserts/Pasted%20image%2020250819163638.png)

![](asserts/Pasted%20image%2020250819163738.png)
- 维度为5阶
	- blk
	- k，v
	- 多头注意力头号
	- 上下文token数量
	- dh：一维向量

实际的 AI 编译器中，张量定义中可以 增加一个额外字段记录张量的语义布 局，用于自动布局优化。 
![](asserts/Pasted%20image%2020250819163934.png)


语义相同的张量在地址空间中有多种布局方式。 下图中： 
- 方格的位置表示数据在逻辑上的位置； 
- 方格中的数字表示数据在地址空间中的位置（即指针）
![](asserts/Pasted%20image%2020250819164009.png)