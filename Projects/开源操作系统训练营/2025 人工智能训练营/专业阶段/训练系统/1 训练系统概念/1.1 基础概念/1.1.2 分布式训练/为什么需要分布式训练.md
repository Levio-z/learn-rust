### 模型越大
[2.1 分布式训练中与内存墙](../../../../Atomic%20Notes/内存墙/2.1%20分布式训练中与内存墙.md)

### 从矩阵乘法视角看并行训练范式
Transformer 的核心计算：大量的矩阵乘法（Embedding、Attention、FFN） 矩阵越来越大——单卡放不下/算不动——怎么分？

![](asserts/Pasted%20image%2020250813183803.png)

### 数据并行
Transformer 的核心计算：大量的矩阵乘法（Embedding、Attention、FFN） 矩阵越来越大——单卡放不下/算不动——怎么分？
![](asserts/Pasted%20image%2020250813205057.png)

![](asserts/Pasted%20image%2020250813205142.png)
- 每一轮训练前都要分发参数

- 所有卡都获得最终的梯度

➢通信开销增加 ：每个 step 中的 All-Reduce **通信时间随卡 数上升**，尤其在参数量大时更明显 

➢ 通信带宽受限：GPU 间通信（特别是跨节点）受限于**网络拓扑与带宽**（如 NVLink vs PCIe vs InfiniBand） 

➢ 计算 vs 通信：当模型较小或 batch size 较小时，**通信成本 会“掩盖”计算收益**；提高 batch size 可提高计算/通信比， 但会影响**收敛稳定性** 

➢ 单卡**内存**可能无法支持整个模型的训练数

### 模型并行

- 张量并行：切分对象为层内矩阵（列 / 行），代表方法是 Megatron-LM，通信需求为 AllReduce 通信
- 流水并行：切分对象为层间切分（Stage），代表方法是 Gpipe、PipeDream，通信需求为 Send/Recv 通信
- 专家并行：切分对象为多路径子网络（稀疏），代表方法是 Swich、GShard，通信需求为 AllToAll 全局通信

Transformer 的核心计算：大量的矩阵乘法（Embedding、Attention、FFN） 矩阵越来越大——单卡放不下/算不动——怎么分？

![](asserts/Pasted%20image%2020250813210153.png)

![](asserts/Pasted%20image%2020250813210254.png)

张量并行优点：
➢ 减少权重和中间激活张量的内存占用 
➢ 在一定程度上减少整体的计算时间 

张量并行缺点： 
➢ 通信频繁（中间输出需 AllReduce） 
➢ 将原本的大矩阵切分为小矩阵，可能降低 GPU 矩阵乘效率

![](asserts/Pasted%20image%2020250813210732.png)

### 流水并行

➢ 将网络切分为多个阶段，并分发到不同的计算设备 
➢ 各个计算设备之间以“接力”的方式完成训练 
➢ 在前向传播过程中，每个 GPU 通过 send/recv 将 中间的激活传递给下一个阶段 
➢ 在后向传播过程中，每个 GPU 将输入张量的梯度通 过 send/recv 传回给前一个流水线阶段

![](asserts/Pasted%20image%2020250813210911.png)

每个阶段有依赖，b必须等待a完成

流水并行的关键是减少缝隙

![](asserts/Pasted%20image%2020250813210937.png)

➢ 传统的流水并行方法由于网络的顺序依赖性， 计算资源严重空闲 
➢ GPipe 将一个输入 mini-batch 拆分为更小 的 micro-batch，从而提升并行度 
➢ 梯度在末尾同步更新
![](asserts/Pasted%20image%2020250813211407.png)
https://link.wtturl.cn/?target=https%3A%2F%2Farxiv.org%2Fpdf%2F1909.08053v2&scene=im&aid=497858&lang=zh
更精确的调度，尽可能能装满流水线

➢ Startup State：输入阶段引入 4 个 mini-batch，依次 推进至输出端 

➢ Steady State：输出阶段完成第一个 mini-batch 的前向传播后，立刻开始反向传播，随后每个阶段都交替处理前后向任务，**所有 GPU 在任意时刻都处于工作状态， 没有空闲** 

**在梯度更新上，Gpipe 是同步的，PipeDream 是异步的**（存在参数不一致的问题）



- mini-batch 5 的前向传播使用的是 mini-batch 1 之后更 新的过的参数，而其反向传播是在 mini-batch 2、3、4 的 更新之后进行的，**前后向使用参数不一致会影响模型收敛** 

- ➢ Weight Stashing：**为每个活跃的 mini-batch 保留一 份前向传播时使用的参数副本**，保证单个 stage 内的参 数一致性。 （换训练的稳定性）

### 专家并行
➢ 混合专家系统 MOE (Mixture of Experts)

MoE 就像一个智能分工系统， 给每个输入挑最合适的专家处理， 让大模型既聪明又节能

➢ 混合专家系统 MOE (Mixture of Experts) 
➢ 允许不增加每个样本计算量的同时，增大模型参数量
![](asserts/Pasted%20image%2020250813211804.png)

![](asserts/Pasted%20image%2020250813212011.png)
➢ 需要与数据并行结合，对输入数据划分
➢ 专家划分到不同设备上 
➢ 引入 All-to-All 全局通信 Gate Token 


引入 MoE 扩展的 Transformer 结构
![](asserts/Pasted%20image%2020250813212216.png)
 - [1]Lepikhin D, Lee H J, Xu Y, et al. Gshard: Scaling giant models with conditional computation and automatic sharding[J]. arXiv preprint arXiv:2006.16668, 2020
 
 ➢ 标准的 Transformer 编码器由 Self-Attention 与 Feed-Forward 交替堆叠，并辅以残差连接 与层归一化 
 ➢ 将编码器中**每隔一个前馈层替换为 MoE 层**后， 即可得到 MoE Transformer 编码器的结构 
 ➢ 当将模型扩展到多设备时，**MoE 层会被划分并 分布到多个设备上**，而其他层则仍然在每个设 备上完整复制

![](asserts/Pasted%20image%2020250813213001.png)
MoE 中的 Gate 会根据输入动态选择一小部分专家 
➢ 存在负载不均衡问题，部分专家被频繁选择，部分很少被使用 
➢ 导致某些 GPU 非常忙，而其他 GPU 空闲


解决方法： 
➢ 路由策略优化：Top-2 Gating、Single-Expert Gating、 Top-K Gating、Correlation-Aware Gating… 
➢ 辅助损失（Auxiliary Loss）：用来惩罚专家间使用不均 
➢ 容量约束（Capacity Constraints）：设置专家的最大 token(超过就丢弃，或者分给其他的)
### 如何选择合适的并行策略组合非常挑战
以 GPT3 为例，采用多种并行策略混用进行训练： 
➢ 首先被分为 64 个阶段，进行**流水并行**训练，每个阶段 都运行在 6 台 DGX-A100 主机上
➢ 在 6 台主机之间，进行的是**数据并行**训练 
➢ 每台主机有 8 张 GPU 显卡，同一台机器上的 8 张 GPU 显卡之间是进行**张量并行**训练
![](asserts/Pasted%20image%2020250813214538.png)



➢ 不同的并行策略的通信需求和计算模式不同 
➢ 数据并行、模型并行、流水并行、MoE 并行 
➢ 底层不同的网络拓扑结构会对性能有很大影响

[1] https://docs.oneflow.org/master/parallelism/01_introduction.html