我们将数据流与控制流解耦，以有效地使用网络。 当控制从客户端流向主服务器，然后流向所有辅助服务器时，数据以流水线方式沿着精心挑选的块服务器链线性推送。我们的目标是**充分利用每台机器的网络带宽，避免网络瓶颈和高延迟链路，并最大限度地减少延迟以推送所有数据**。

**为了充分利用每台机器的网络带宽，数据沿着块服务器链线性推送，而不是分布在其他拓扑（例如树）中。因此，每台机器的全部出站带宽用于尽可能快地传输数据，而不是在多个接收者之间分配。**

为了尽可能避免网络瓶颈和高延迟链路（例如，交换机间链路通常两者兼而有之），每台**机器都会将数据转发到网络拓扑中尚未接收数据的“最近”机器**。 假设客户端正在将数据推送到块服务器 S1 到 S4。 它将数据发送到最近的块服务器，例如 S1。S1 将其转发到最近的块服务器 S2 到 S4 最接近 S1，例如 S2。同样，S2 将其转发到 S3 或 S4，以较接近 S2 为准，依此类推。我们的网络拓扑非常简单，可以从 IP 地址准确估计“距离”。

最后，我们通过通过 TCP 连接流水线传输数据来最大限度地减少延迟。一旦 chunkserver 收到一些数据，它就会立即开始转发。流水线对我们特别有帮助，因为我们使用具有全双工链路的交换网络。立即发送数据不会降低接收速率。在没有网络拥塞的情况下，将 B 字节传输到 R 副本的理想经过时间是 B/T + RL，其中 T 是网络吞吐量，L 是在两台机器之间传输字节的延迟。我们的网络链路通常为 100 Mbps （T），L 远低于 1 毫秒。因此，理想情况下，1 MB 可以在大约 80 毫秒内分配。

