### 什么是时间复杂度

**数据结构与算法解决的是让代码运行更快、更省空间的问题，而衡量算法执行效率的重要指标就是时间复杂度和空间复杂度，它们表示代码执行时间和空间使用随数据规模增长的变化趋势。**
### 为什么需要有复杂度分析
通过统计、监控可以直接得到算法执行的时间和占用内存的大小，为什么还需要做时间、空间复杂度分析。这种比直接跑一遍数据更准确吗？
这种评估算法执行效率的方法是正确的。但是有局限性。
**1、测试结果非常依赖执行环境**
硬件的不同会对测试结果产生很大的影响
**2、测试结果受数据规模的影响很大**
举个例子，对同一个排序算法，待排序的有序度不一样，排序的执行时间就会有很大的差别。如果测试数据规模太小，无法真实反应算法的性能，比如，对于小规模的数据，插入排序可能会比快速排序要快！

我们需要⼀个不⽤具体的测试数据来测试，就可以粗略地估计算法的执⾏效率的⽅法

### 大O复杂度表示法
```
int cal(int n) {
    int sum = 0;
    int i;

    for (i = 1; i <= n; ++i) {
        sum = sum + i;
    }

    return sum;
}

```

从CPU的⻆度来看，这段代码的每⼀⾏都执⾏着类似的操作：读数据-运算-写数据。尽管每⾏代码对应的CPU执⾏的个数、执 ⾏的时间都不⼀样，但是，我们这⾥只是粗略估计，所以可以**假设每⾏代码执⾏的时间都⼀样，为unit_time。在这个假设的基础之上，这段代码的总执⾏时间是多少呢？**

第2、3⾏代码分别需要1个unit_time的执⾏时间，第4、5⾏都运⾏了n遍，所以需要2n*unit_time的执⾏时间，所以这段代码总 的执⾏时间就是(2n+2)*unit_time。可以看出来，所有代码的执⾏时间T(n)与每⾏代码的执⾏次数成正⽐。

按照这个分析思路，我们再来看这段代码。
```
int cal(int n) {
    int sum = 0;
    int i, j;

    for (i = 1; i <= n; ++i) {
	    j = 1;
        for (j = 1; j <= n; ++j) {
            sum = sum + i * j;
        }
    }

    return sum;
}
```
第2、3、4⾏代码，每⾏都需要1个unit_time的执⾏时间，第5、6⾏代码循环执⾏了n遍，需要2n * unit_time的执⾏时间，第7、8⾏代码循环执⾏了n 遍，所以需要2*$n^2$* unit_time的执⾏时间。所以，整段代码总的执⾏时间T(n) = (2$n^2$ +2n+3)*unit_time。
#### 1、所有代码的执⾏时间T(n)与每⾏代码的执⾏次数n成正⽐
尽管我们不知道unit_time的具体值，但是通过这两段代码执⾏时间的推导过程，我们可以得到⼀个⾮常重要的规律，那就 是，**所有代码的执⾏时间T(n)与每⾏代码的执⾏次数n成正⽐。**

我们可以把这个规律总结成⼀个公式。注意，⼤O就要登场了！
![](asserts/Pasted%20image%2020250723212709.png)
- T(n)我们已经讲过了，它表示代码执⾏的时间；
- n表示数据规模的⼤⼩；
- f(n)表示每⾏代码执⾏的次数总和。因为这是⼀个公式，所以⽤f(n)来表示。
- **公式中的O，表示代码的执⾏时间T(n)与f(n)表达式成正⽐。**
#### 2. **⼤O时间复杂度**实际上并不具体表示代码真正的执⾏时间，⽽是表示**代码执⾏时间随数据规模增⻓的变化趋势**
所以，第⼀个例⼦中的T(n) = O(2n+2)，第⼆个例⼦中的T(n) = O(2n +2n+3)。这就是⼤O时间复杂度表示法。**⼤O时间复杂度**实际上并不具体表示代码真正的执⾏时间，⽽是表示**代码执⾏时间随数据规模增⻓的变化趋势**，所以，也叫作渐进时间复杂 度（asymptotic time complexity），简称时间复杂度。
>我们关注的不是**精确的执行时间**，而是：**数据规模变大时，程序运行时间大致增长得有多快**。

#### 3.**低阶、常量、系数三部分并不左右增⻓趋势**
- 当n很⼤时，你可以把它想象成10000、100000。⽽公式中的低阶、常量、系数三部分并不左右增⻓趋势，所以都可以忽略。 我们只需要记录⼀个最⼤量级就可以了，如果⽤⼤O表示法表示刚讲的那两段代码的时间复杂度，就可以记为：T(n) = O(n)； T(n) = O($n^2$ )。
### 时间复杂度分析
#### 1.只关注循环执⾏次数最多的⼀段代码

我刚才说了，⼤O这种复杂度表示⽅法只是表示⼀种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录⼀ 个最⼤阶的量级就可以了。所以，**我们在分析⼀个算法、⼀段代码的时间复杂度的时候，也只关注循环执⾏次数最多的那⼀段 代码就可以了**。这段核⼼代码执⾏次数的n的量级，就是整段要分析代码的时间复杂度。
```
int cal(int n) {
    int sum = 0;
    int i;

    for (i = 1; i <= n; ++i) {
        sum = sum + i;
    }

    return sum;
}
```
其中第2、3⾏代码都是常量级的执⾏时间，与n的⼤⼩⽆关，所以对于复杂度并没有影响。循环执⾏次数最多的是第4、5⾏代 码，所以这块代码要重点分析。前⾯我们也讲过，这两⾏代码被执⾏了n次，所以总的时间复杂度就是O(n)。

#### 2.加法法则：总复杂度等于量级最⼤的那段代码的复杂度
我这⾥还有⼀段代码。你可以先试着分析⼀下，然后再往下看跟我的分析思路是否⼀样。
```
int cal(int n) {
    int sum_1 = 0;
    for (int p = 1; p < 100; ++p) {
        sum_1 += p;
    }

    int sum_2 = 0;
    for (int q = 1; q < n; ++q) {
        sum_2 += q;
    }

    int sum_3 = 0;
    for (int i = 1; i <= n; ++i) {
        for (int j = 1; j <= n; ++j) {
            sum_3 += i * j;
        }
    }

    return sum_1 + sum_2 + sum_3;
}

```
- 分析第一段
	- 第⼀段的时间复杂度是多少呢？这段代码循环执⾏了100次，所以是⼀个常量的执⾏时间，跟n的规模⽆关。
	- 这⾥我要再强调⼀下，即便这段代码循环10000次、100000次，只要是⼀个已知的数，跟n⽆关，照样也是常量级的执⾏时 间。当n⽆限⼤的时候，就可以忽略。尽管对代码的执⾏时间会有很⼤影响，但是回到时间复杂度的概念来说，它表示的是⼀ 个算法执⾏效率与数据规模增⻓的变化趋势，所以不管常量的执⾏时间多⼤，我们都可以忽略掉。因为**它本身对增⻓趋势并没 有影响。**
- 那第⼆段代码和第三段代码的时间复杂度是多少呢？答案是O(n)和O($n^2$ )，你应该能容易就分析出来，我就不啰嗦了。
- 总的时间复杂 度就等于量级最⼤的那段代码的时间复杂度。

$T1(n)=O(f(n))，T2(n)=O(g(n)),T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n))).$
#### 3.乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积
```
int f(int n) {
    int sum = 0;
    for (int i = 1; i < n; ++i) {
        sum += i;
    }
    return sum;
}

int cal(int n) {
    int ret = 0;
    for (int i = 1; i < n; ++i) {
        ret += f(i);
    }
    return ret;
}

```
$我们单独看cal()函数。假设f()只是⼀个普通的操作，那第4～6⾏的时间复杂度就是，$$T1(n) = O(n)。但f()函数本身不是⼀个简 单的操作，它的时间复杂度是T2(n) = O(n)，$$所以，整个cal()函数的时间复杂度就是，T(n) = T1(n) * T2(n) = O(n*n) = O(n^2 )。$
### 几种常用的时间复杂度分析
![](asserts/Pasted%20image%2020250723214406.png)
对于刚罗列的复杂度量级，我们可以粗略地分为两类，多项式量级和⾮多项式量级。其中，**⾮多项式量级只有两个：O($2^n$ )和 O(n!)。**

当数据规模n越来越⼤时，**⾮多项式量级算法的执⾏时间会急剧增加，求解问题的执⾏时间会⽆限增⻓**。所以，⾮多项式时间 复杂度的算法其实是⾮常低效的算法。因此，关于NP时间复杂度我就不展开讲了。我们主要来看⼏种常⻅的多项式时间复杂度

### 1. O(1)
⾸先你必须明确⼀个概念，O(1)只是常量级时间复杂度的⼀种表示⽅法，并不是指只执⾏了⼀⾏代码。⽐如这段代码，即便有 3⾏，它的时间复杂度也是O(1），⽽不是O(3)。
```
int i = 8; 
int j = 6;
int sum = i + j;
```
只要代码的执⾏时间不随n的增⼤⽽增⻓，这样代码的时间复杂度我们都记作O(1)。或者说，⼀般情况下， 只要算法中不存在循环语句、递归语句，即使有成千上万⾏的代码，其时间复杂度也是Ο(1)。

### 2. O(logn)、O(nlogn)
对数阶时间复杂度⾮常常⻅，同时也是最难分析的⼀种时间复杂度。我通过⼀个例⼦来说明⼀下。
```
i=1; 
while (i <= n) {
i = i * 2;
}
```
根据我们前⾯讲的复杂度分析⽅法，第三⾏代码是循环执⾏次数最多的。所以，我们只要能计算出这⾏代码被执⾏了多少次，就能知道整段代码的时间复杂度。

从代码中可以看出，变量i的值从1开始取，每循环⼀次就乘以2。当⼤于n时，循环结束。还记得我们⾼中学过的等⽐数列吗？ 实际上，变量i的取值就是⼀个等⽐数列。如果我把它⼀个⼀个列出来，就应该是这个样⼦的：
![](asserts/Pasted%20image%2020250723214716.png)
所以，我们只要知道x值是多少，就知道这⾏代码执⾏的次数了。通过2 =n求解x这个问题我们想⾼中应该就学过了，我就不多 说了。x=log n，所以，这段代码的时间复杂度就是O(log n)。

现在，我把代码稍微改下，你再看看，这段代码的时间复杂度是多少？

```
i=1; while (i <= n) { i = i * 3; }
```
根据我刚刚讲的思路，很简单就能看出来，这段代码的时间复杂度为O($\log_{3}n$)。
$在采⽤⼤O标记复杂度的时候，可以忽略系数，即O(Cf(n)) = O(f(n))$
$如果⼀段代码的时间复杂度 是O(logn)，我们循环执⾏n遍，时间复杂度就是O(nlogn)了$$O(nlogn)也是⼀种⾮常常⻅的算法时间复杂度。⽐如，归 并排序、快速排序的时间复杂度都是O(nlogn)。$
### 3. O(m+n)、O(m*n)
代码的复杂度由两个数据的规模来决定
```
int cal(int m, int n) {
    int sum_1 = 0;
    // 计算从1到m-1的和
    for (int i = 1; i < m; ++i) {
        sum_1 += i;
    }

    int sum_2 = 0;
    // 计算从1到n-1的和
    for (int j = 1; j < n; ++j) {
        sum_2 += j;
    }

    // 返回两个和的总和
    return sum_1 + sum_2;
}

```

我们⽆法事先评估m和n谁的量级⼤，所以我们在表示复杂度的时候，就不能 简单地利⽤加法法则，省略掉其中⼀个。所以，上⾯代码的时间复杂度就是O(m+n)。

针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续 有效：T1(m)*T2(n) = O(f(m) * f(n))。

### 空间复杂度分析

前⾯，咱们花了很⻓时间讲⼤O表示法和时间复杂度分析，理解了前⾯讲的内容，空间复杂度分析⽅法学起来就⾮常简单了。 前⾯我讲过，时间复杂度的全称是渐进时间复杂度，表示算法的执⾏时间与数据规模之间的增⻓关系。类⽐⼀下，空间复杂度 全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增⻓关系。
```
public void print(int n) {
	int i = 0;
    int[] a = new int[n];
    for (int i = 0; i < n; i++) {
        a[i] = i * i;
    }
    for (int i = n - 1; i >= 0; i--) {
        System.out.println(a[i]);
    }
	}
```
跟时间复杂度分析⼀样，我们可以看到，第2⾏代码中，我们申请了⼀个空间存储变量i，但是它是常量阶的，跟数据规模n没 有关系，所以我们可以忽略。第3⾏申请了⼀个⼤⼩为n的int类型数组，除此之外，剩下的代码都没有占⽤更多的空间，所以整段代码的空间复杂度就是O(n)。
### 内容⼩结

基础复杂度分析的知识到此就讲完了，我们来总结⼀下。

复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，⽤来分析算法执⾏效率与数据规模之间的增⻓关系，可以粗略地表 示，越⾼阶复杂度的算法，执⾏效率越低。常⻅的复杂度并不多，从低阶到⾼阶有：O(1)、O(logn)、O(n)、O(nlogn)、O($n^2$ )。等你学完整个专栏之后，你就会发现⼏乎所有的数据结构和算法的复杂度都跑不出这⼏个。
![](asserts/Pasted%20image%2020250723221457.png)

复杂度分析并不难，关键在于多练。 之后讲后⾯的内容时，我还会带你详细地分析每⼀种数据结构和算法的时间、空间复杂 度。只要跟着我的思路学习、练习，你很快就能和我⼀样，每次看到代码的时候，简单的⼀眼就能看出其复杂度，难的稍微分 析⼀下就能得出答案。
### 课后思考
有⼈说，我们项⽬之前都会进⾏性能测试，再做代码的时间复杂度、空间复杂度分析，是不是多此⼀举呢？⽽且，每段代码都 分析⼀下时间复杂度、空间复杂度，是不是很浪费时间呢？你怎么看待这个问题呢？