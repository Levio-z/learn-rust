```
// 基于数组实现的顺序栈
public class ArrayStack {
    private String[] items; // 栈的底层存储数组
    private int count;      // 当前栈中元素个数
    private int n;          // 栈的最大容量

    // 构造函数：初始化数组，并设置容量 n
    public ArrayStack(int n) {
        this.items = new String[n];
        this.n = n;
        this.count = 0;
    }

    // 入栈操作：将 item 推入栈顶
    public boolean push(String item) {
        // 如果栈已满，返回 false 表示入栈失败
        if (count == n) return false;

        // 插入元素到栈顶，并更新元素计数
        items[count] = item;
        count++;
        return true;
    }

    // 出栈操作：移除并返回栈顶元素
    public String pop() {
        // 如果栈为空，返回 null 表示无法出栈
        if (count == 0) return null;

        // 返回栈顶元素，并更新元素计数
        String top = items[count - 1];
        count--;
        return top;
    }
}
```
了解了定义和基本操作，那它的操作的时间、空间复杂度是多少呢？

不管是顺序栈还是链式栈，我们存储数据只需要一个大小为n的数组就够了。在入栈和出栈过程中，只需要一两个临时变量存储空间，所以空间复杂度是O(1)。

注意，这里存储数据需要一个大小为n的数组，并不是说空间复杂度就是O(n)。因为，这n个空间是必须的，无法省掉。所以我们说空间复杂度的时候，是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。

空间复杂度分析是不是很简单？时间复杂度也不难。不管是顺序栈还是链式栈，入栈、出栈只涉及栈顶个别数据的操作，所以时间复杂度都是O(1)。

### 支持动态扩容的顺序栈
刚才那个基于数组实现的栈，是一个固定大小的栈，也就是说，在初始化栈时需要事先指定栈的大小。当栈满之后，就无法再往栈里添加数据了。尽管链式栈的大小不受限，但要存储next指针，内存消耗相对较多。那我们如何基于数组实现一个可以支持动态扩容的栈呢？

你还记得，我们在数组那一节，是如何来实现一个支持动态扩容的数组的吗？当数组空间不够时，我们就重新申请一块更大的内存，将原来数组中数据统统拷贝过去。这样就实现了一个支持动态扩容的数组。

所以，如果要实现一个支持动态扩容的栈，我们只需要底层依赖一个支持动态扩容的数组就可以了。当栈满了之后，我们就申请一个更大的数组，将原来的数据搬移到新数组中。我画了一张图，你可以对照着理解一下。
![](asserts/Pasted%20image%2020250803104937.png)

实际上，支持动态扩容的顺序栈，我们平时开发中并不常用到。我讲这一块的目的，主要还是希望带你练习一下前面讲的复杂度分析方法。所以这一小节的重点是复杂度分析。

你不用死记硬背入栈、出栈的时间复杂度，你需要掌握的是分析方法。能够自己分析才算是真正掌握了。现在我就带你分析一下支持动态扩容的顺序栈的入栈、出栈操作的时间复杂度。

对于出栈操作来说，我们不会涉及内存的重新申请和数据的搬移，所以出栈的时间复杂度仍然是O(1)。但是，对于入栈操作来说，情况就不一样了。当栈中有空闲空间时，入栈操作的时间复杂度为O(1)。但当空间不够时，就需要重新申请内存和数据搬移，所以时间复杂度就变成了O(n)。

也就是说，对于入栈操作来说，最好情况时间复杂度是O(1)，最坏情况时间复杂度是O(n)。那平均情况下的时间复杂度又是多少呢？还记得我们在复杂度分析那一节中讲的摊还分析法吗？这个入栈操作的平均情况下的时间复杂度可以用摊还分析法来分析。我们也正好借此来实战一下摊还分析法。

为了分析的方便，我们需要事先做一些假设和定义：

- 栈空间不够时，我们重新申请一个是原来大小两倍的数组；
    
- 为了简化分析，假设只有入栈操作没有出栈操作；
    
- 定义不涉及内存搬移的入栈操作为simple-push操作，时间复杂度为O(1)。

如果当前栈大小为K，并且已满，当再有新的数据要入栈时，就需要重新申请2倍大小的内存，并且做K个数据的搬移操作，然后再入栈。但是，接下来的K-1次入栈操作，我们都不需要再重新申请内存和搬移数据，所以这K-1次入栈操作都只需要一个simple-push操作就可以完成。为了让你更加直观地理解这个过程，我画了一张图。

![](asserts/Pasted%20image%2020250803105107.png)

你应该可以看出来，这K次入栈操作，总共涉及了K个数据的搬移，以及K次simple-push操作。将K个数据搬移均摊到K次入栈操作，那每个入栈操作只需要一个数据搬移和一个simple-push操作。以此类推，入栈操作的均摊时间复杂度就为O(1)。

通过这个例子的实战分析，也印证了前面讲到的，均摊时间复杂度一般都等于最好情况时间复杂度。因为在大部分情况下，入栈操作的时间复杂度O都是O(1)，只有在个别时刻才会退化为O(n)，所以把耗时多的入栈操作的时间均摊到其他入栈操作上，平均情况下的耗时就接近O(1)。

通过这个例子的实战分析，也印证了前面讲到的，均摊时间复杂度一般都等于最好情况时间复杂度。因为在大部分情况下，入栈操作的时间复杂度O都是O(1)，只有在个别时刻才会退化为O(n)，所以把耗时多的入栈操作的时间均摊到其他入栈操作上，平均情况下的耗时就接近O(1)。

### 栈在函数调用中的应用
前面我讲的都比较偏理论，我们现在来看下，栈在软件工程中的实际应用。栈作为一个比较基础的数据结构，应用场景还是蛮多的。其中，比较经典的一个应用场景就是**函数调用栈**。

我们知道，操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构,用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。为了让你更好地理解，我们一块来看下这段代码的执行过程。

### 栈在表达式求值中的应用
了方便解释，我将算术表达式简化为只包含加减乘除四则运算，比如：34+13*9+44-12/3。对于这个四则运算，我们人脑可以很快求解出答案，但是对于计算机来说，理解这个表达式本身就是个挺难的事儿。如果换作你，让你来实现这样一个表达式求值的功能，你会怎么做呢？

实际上，编译器就是通过两个栈来实现的。其中一个保存操作数的栈，另一个是保存运算符的栈。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。

如果**比运算符栈顶元素的优先级高，就将当前运算符压入栈**；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取2个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。

我将3+5*8-6这个表达式的计算过程画成了一张图，你可以结合图来理解我刚讲的计算过程。
![](asserts/Pasted%20image%2020250803105544.png)

### 栈在括号匹配中的应用
除了用栈来实现表达式求值，我们还可以借助栈来检查表达式中的括号是否匹配。



这里也可以用栈来解决。我们用栈来保存未匹配的左括号，从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，比如“(”跟“)”匹配，“`[`”跟“`]`”匹配，“{”跟“}”匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。

当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。

### 解答开篇
好了，我想现在你已经完全理解了栈的概念。我们再回来看看开篇的思考题，如何实现浏览器的前进、后退功能？其实，用两个栈就可以非常完美地解决这个问题。

我们使用两个栈，X和Y，我们把首次浏览的页面依次压入栈X，当点击后退按钮时，再依次从栈X中出栈，并将出栈的数据依次放入栈Y。当我们点击前进按钮时，我们依次从栈Y中取出数据，放入栈X中。当栈X中没有数据时，那就说明没有页面可以继续后退浏览了。当栈Y中没有数据，那就说明没有页面可以点击前进按钮浏览了。

比如你顺序查看了a，b，c三个页面，我们就依次把a，b，c压入栈，这个时候，两个栈的数据就是这个样子：
![](asserts/Pasted%20image%2020250803110338.png)
当你通过浏览器的后退按钮，从页面c后退到页面a之后，我们就依次把c和b从栈X中弹出，并且依次放入到栈Y。这个时候，两个栈的数据就是这个样子：
![](asserts/Pasted%20image%2020250803110350.png)
这个时候你又想看页面b，于是你又点击前进按钮回到b页面，我们就把b再从栈Y中出栈，放入栈X中。此时两个栈的数据是这个样子：
![](asserts/Pasted%20image%2020250803110501.png)
这个时候，你通过页面b又跳转到新的页面d了，页面c就无法再通过前进、后退按钮重复查看了，所以需要清空栈Y。此时两个栈的数据这个样子：
![](asserts/Pasted%20image%2020250803110526.png)
### 一、为什么函数调用要用“栈”保存临时变量？能不能用别的数据结构？
首先：函数调用的本质是“嵌套 + 回退”，这非常适合“栈”的**后进先出（LIFO）**特性。
```
main() 调用 → funcA() 调用 → funcB()
                     ↖ 返回 ← 返回 ←.
```
#### ✅ 栈带来的好处：

1. **结构简单、效率高**：入栈、出栈都是 O(1) 操作，编译器或虚拟机只需要维护一个栈指针。
    
2. **作用域清晰、自动清理**：每次函数调用就开辟一个“栈帧”，函数返回时自动回收，无需手动释放。
    
3. **线程私有、无锁竞争**：每个线程独享一个调用栈，不需要加锁或同步。

### 二、JVM中的“栈”是不是我们这里讲的“栈”？为什么也叫栈？

#### ✅ 相同点：**概念是一致的，结构也是“栈”。**

- JVM 里的“Java 虚拟机栈”，每次方法调用都会创建一个**栈帧（Stack Frame）**，用于保存局部变量、操作数栈、返回地址等。
    
- 每个线程有自己独立的调用栈，这些栈帧正是**以“栈”的方式管理**的。
    

所以，从结构和用途上讲，**JVM 栈就是我们说的“调用栈”在 Java 虚拟机中的实现形式**。

```
|-------------------------| ← 栈顶
|   方法C的栈帧（局部变量 + 返回地址） |
|-------------------------|
|   方法B的栈帧                 |
|-------------------------|
|   方法A的栈帧                 |
|-------------------------| ← 栈底

```

> **函数调用需要“回退”的结构，而“栈”就是最天然、最高效的回退机制。**

无论是在裸机程序中维护的函数调用栈，还是 JVM 中维护的虚拟机栈，本质上都是一种**后进先出（LIFO）模型的调用上下文管理结构**，而“栈”正是这个模型的自然载体。