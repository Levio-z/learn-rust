### 如何实现随机访问？
数组（Array）是⼀种线性表数据结 构。它⽤⼀组连续的内存空间，来存储⼀组具有相同类型的数据。

第⼀是线性表（Linear List）。顾名思义，线性表就是**数据排成像⼀条线⼀样的结构**。每个**线性表上的数据最多只有前和后两 个⽅向**。其实除了数组，链表、队列、栈等也是线性表结构。

![](asserts/Pasted%20image%2020250725204209.png)
⽽与它相对⽴的概念是⾮线性表，⽐如⼆叉树、堆、图等。之所以叫⾮线性，是因为，在⾮线性表中，数据之间并不是简单的 前后关系。
![](asserts/Pasted%20image%2020250725204234.png)
第⼆个是**连续的内存空间和相同类型的数据**。正是因为这两个限制，它才有了⼀个堪称“杀⼿锏”的特性：“随机访问”。但有利 就有弊，这两个限制也让数组的很多操作变得⾮常低效，⽐如要想在数组中删除、插⼊⼀个数据，为了保证连续性，就需要做 ⼤量的数据搬移⼯作。
我们拿⼀个⻓度为10的int类型的数组int[] a = new int`[10]`来举例。在我画的这个图中，计算机给数组a`[10]`，分配了⼀块连续内 存空间1000～1039，其中，内存块的⾸地址为base_address = 1000。
![](asserts/Pasted%20image%2020250725204400.png)
计算机会给每个内存单元分配⼀个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某 个元素时，它会⾸先通过下⾯的寻址公式，计算出该元素存储的内存地址：
```
a[i]_address = base_address + i * data_type_size
```
其中data_type_size表示数组中每个元素的⼤⼩。我们举的这个例⼦⾥，数组中存储的是int类型数据，所以data_type_size就 为4个字节。这个公式⾮常简单，我就不多做解释了。

这⾥我要特别纠正⼀个“错误”。我在⾯试的时候，常常会问数组和链表的区别，很多⼈都回答说，“链表适合插⼊、删除，时间 复杂度O(1)；数组适合查找，查找时间复杂度为O(1)”。

实际上，这种表述是不准确的。数组是适合查找操作，但是查找的时间复杂度并不为O(1)。即便是排好序的数组，你⽤⼆分查找，时间复杂度也是O(logn)。所以，正确的表述应该是，数组⽀持随机访问，根据下标随机访问的时间复杂度为O(1)。

### 低效的“插⼊”和“删除”

前⾯概念部分我们提到，数组为了保持内存数据的连续性，会导致插⼊、删除这两个操作⽐较低效。现在我们就来详细说⼀ 下，究竟为什么会导致低效？⼜有哪些改进⽅法呢？ 我们先来看插⼊操作

假设数组的⻓度为n，现在，如果我们需要将⼀个数据插⼊到数组中的第k个位置。为了把第k个位置腾出来，给新来的数据， 我们需要将第k～n这部分的元素都顺序地往后挪⼀位。那插⼊操作的时间复杂度是多少呢？你可以⾃⼰先试着分析⼀下。

#### 数组中的数据是有序的时间复杂度分析

如果在数组的末尾插⼊元素，那就不需要移动数据了，这时的时间复杂度为O(1)。但如果在数组的开头插⼊元素，那所有的数 据都需要依次往后移动⼀位，所以最坏时间复杂度是O(n)。 因为我们在每个位置插⼊元素的概率是⼀样的，所以平均情况时 间复杂度为(1+2+…n)/n=O(n)。

如果数组中的数据是有序的，我们在某个位置插⼊⼀个新的元素时，就必须按照刚才的⽅法搬移k之后的数据。但是，如果数 组中存储的数据并没有任何规律，数组只是被当作⼀个存储数据的集合。在这种情况下，如果要将某个数组插⼊到第k个位

#### 数组中的数据无序的时间复杂度分析
如果数组中的数据是有序的，我们在某个位置插⼊⼀个新的元素时，就必须按照刚才的⽅法搬移k之后的数据。但是，如果数 组中存储的数据并没有任何规律，数组只是被当作⼀个存储数据的集合。在这种情况下，如果要将某个数组插⼊到第k个位置，为了避免⼤规模的数据搬移，我们还有⼀个简单的办法就是，直接将第k位的数据搬移到数组元素的最后，把新的元素直 接放⼊第k个位置。
为了更好地理解，我们举⼀个例⼦。假设数组a`[10]`中存储了如下5个元素：a，b，c，d，e。 我们现在需要将元素x插⼊到第3个位置。我们只需要将c放⼊到a`[5]`，将a`[2]`赋值为x即可。最后，数组中的元素如下： a，b，x，d，e，c。
![](asserts/Pasted%20image%2020250725204931.png)
利⽤这种处理技巧，在特定场景下，在第k个位置插⼊⼀个元素的时间复杂度就会降为O(1)。这个处理思想在快排中也会⽤ 到，我会在排序那⼀节具体来讲，这⾥就说到这⼉。
### 删除操作

跟插⼊数据类似，如果我们要删除第k个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就 不连续了。 和插⼊类似，如果删除数组末尾的数据，则最好情况时间复杂度为O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为O(n)。

#### 将多次删除操作集中在⼀起执⾏，删除的 效率是不是会提⾼很多呢
为了避免d，e，f，g，h这⼏个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数 据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执⾏⼀次真正的删除操作，这样就⼤⼤减少了删 除操作导致的数据搬移。

如果你了解JVM，你会发现，这不就是JVM标记清除垃圾回收算法的核⼼思想吗？没错，数据结构和算法的魅⼒就在于此，**很 多时候我们并不是要去死记硬背某个数据结构或者算法，⽽是要学习它背后的思想和处理技巧，这些东⻄才是最有价值的**。如 果你细⼼留意，不管是在软件开发还是架构设计中，总能找到某些算法和数据结构的影⼦。

#### 警惕数组的访问越界问题
```
#include <stdio.h>

int main(int argc, char* argv[]) {
    int i = 0;
    int arr[3] = {0}; // 定义长度为 3 的整型数组 arr，初始全部为 0

    // 错误：循环边界条件 i <= 3 会导致数组越界访问 arr[3]
    for (; i <= 3; i++) {
        arr[i] = 0; // 当 i==3 时，将访问越界的 arr[3]
        printf("hello world\n");
    }

    return 0;
}
```
- **循环边界：** `for (; i <= 3; i++)` → `i == 3` 时访问了 `arr[3]`（**越界**）
- **越界后果：** 在某些平台或编译器设置下，`arr[3]` 紧邻变量 `i`，`arr[3] = 0;` 实际上把 `i` 写回了 0，导致死循环。

数组越界在C语⾔中是⼀种未决⾏为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问⼀段 连续内存，只要数组通过偏移计算得到的内存地址是可⽤的，那么程序就可能不会报任何错误。 这种情况下，⼀般都会出现莫名其妙的逻辑错误，就像我们刚刚举的那个例⼦，debug的难度⾮常的⼤。⽽且，很多计算机病 毒也正是利⽤到了代码中的数组越界可以访问⾮法地址的漏洞，来攻击系统，所以写代码的时候⼀定要警惕数组越界。 但并⾮所有的语⾔都像C⼀样，把数组越界检查的⼯作丢给程序员来做，像Java本身就会做越界检查，⽐如下⾯这⼏⾏Java代 码，就会抛出java.lang.ArrayIndexOutOfBoundsException。
### 容器能否完全替代数组？
##### 将很多数组操作的细节封装&动态扩容
我个⼈觉得，ArrayList最⼤的优势就是可以将很多数组操作的细节封装起来。⽐如前⾯提到的数组插⼊、删除数据时需要搬移 其他数据等。另外，它还有⼀个优势，就是⽀持动态扩容。
#### 在创建ArrayList的时候事先指定数据⼤⼩，避免扩容的开销。

⽐如我们要从数据库中取出10000条数据放⼊ArrayList。我们看下⾯这⼏⾏代码，你会发现，相⽐之下，事先指定数据⼤⼩可 以省掉很多次内存申请和数据搬移操作。
```
ArrayList users = new ArrayList(10000);
for (int i = 0; i < 10000; ++i) { users.add(xxx); }
```

1.Java ArrayList**⽆法存储基本类型**，⽐如int、long，需要封装为Integer、Long类，⽽Autoboxing、Unboxing则有⼀定的性能 消耗，所以如果特别关注性能，或者希望使⽤基本类型，就可以选⽤数组。
2.如果**数据⼤⼩事先已知，并且对数据的操作⾮常简单，⽤不到ArrayList提供的⼤部分⽅法**，也可以直接使⽤数组。 
3.还有⼀个是我个⼈的喜好，当要表示**多维数组时，⽤数组往往会更加直观**。⽐如Object[][] array；⽽⽤容器的话则需要这样 定义：ArrayList array。

我总结⼀下，对于业务开发，直接使⽤容器就⾜够了，省时省⼒。毕竟损耗⼀丢丢性能，完全不会影响到系统整体的性能。但 如果你是做⼀些⾮常底层的开发，⽐如开发⽹络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为⾸选。
### 为什么数组从0开始

从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。前⾯也讲到，如果⽤a来表示数组的⾸地址，a`[0]` 就是偏移为0的位置，也就是⾸地址，a`[k]`就表示偏移k个type_size的位置，所以计算a`[k]`的内存地址只需要⽤这个公式：
```
a[k]_address = base_address + k * type_size
```
但是，如果数组从1开始计数，那我们计算数组元素a[k]的内存地址就会变为：
```
a[k]_address = base_address + (k-1)*type_size
```
对⽐两个公式，我们不难发现，从1开始编号，每次随机访问数组元素都多了⼀次减法运算，对于CPU来说，就是多了⼀次减 法指令。

**数组作为⾮常基础的数据结构，通过下标随机访问数组元素⼜是其⾮常基础的编程操作，效率的优化就要尽可能做到极致。所 以为了减少⼀次减法操作，数组选择了从0开始编号，⽽不是从1开始。**

不过我认为，上⾯解释得再多其实都算不上压倒性的证明，说数组起始编号⾮0开始不可。所以我觉得最主要的原因可能是历 史原因。

C语⾔设计者⽤0开始计数数组下标，之后的Java、JavaScript等⾼级语⾔都效仿了C语⾔，或者说，为了在⼀定程度上减少C 语⾔程序员学习Java的学习成本，因此继续沿⽤了从0开始计数的习惯。实际上，很多语⾔中数组也并不是从0开始计数的， ⽐如Matlab。甚⾄还有⼀些语⾔⽀持负数下标，⽐如Python。

### 内容⼩结
我们今天学习了数组。它可以说是最基础、最简单的数据结构了。数组⽤⼀块连续的内存空间，来存储相同类型的⼀组数据， 最⼤的特点就是⽀持随机访问，但插⼊、删除操作也因此变得⽐较低效，平均情况时间复杂度为O(n)。在平时的业务开发中， 我们可以直接使⽤编程语⾔提供的容器类，但是，如果是特别底层的开发，直接使⽤数组可能会更合适。

数组
- 线性表，只有前后两个方向
- 续的内存空间和相同类型的数据**
	- 保证了随机访问
		- 底层：计算地址`a[i]_address = base_address + i * data_type_size`
	- 特点：
		- 数组⽀持随机访问，根据下标随机访问的时间复杂度为O(1)
		- 查找，时间复杂度也是O(logn)，插入和删除的时间复杂度为O(n)
- 插入
	- 有序数组插入的时间复杂度O(n)
	- 无序插入将时间复杂度度变为O(1)
		- 在这种情况下，如果要将某个数组插⼊到第k个位置，为了避免⼤规模的数据搬移，我们还有⼀个简单的办法就是，直接将第k位的数据搬移到数组元素的最后，把新的元素直 接放⼊第k个位置。
- 删除
	- 复杂度同插入为O(n)
	- 多次删除是否会效率更高
		- 每次的删除操作并不是真正地搬移数 据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执⾏⼀次真正的删除操作，这样就⼤⼤减少了删 除操作导致的数据搬移。
- 数组越界
	- 未决行为，对于c来说
- 容器能否代替数组
	- 是高级抽象：
		- 数组操作的细节封装&动态扩容
			- 缺点
				- java无法存储基本类型
				- 操作简单
				- 二维数组
	- 动态扩容：优先指定大小，避免扩容的性能损耗
	- 业务开发：优先容器
	- 底层开发：优先数组
- 为什么从0开始
	- 计算`a[k]`的内存地址相比从1开始少一次加法运算
	- C语言从0开始，后者受C影响