## 并发性与并行性：理解资源调度与利用的本质

在现代计算体系中，并发性（**Concurrency**）与并行性（**Parallelism**）是构建高性能系统的核心概念，二者既密切相关又本质不同。

### 并发性：**协调多个任务对资源的访问**

并发强调\*\*“正确地处理多个任务在共享资源上的交错执行”**，即如何在多个活动任务之间高效、安全地调度资源。其关注点是**结构性**与**正确性\*\*，而非物理上的同时运行。

并发的关键挑战在于**共享的**、**可变的状态**资源，例如：

-   多线程访问的内存数据结构；
-   多进程共享的数据库连接；
-   多用户同时写入的日志文件；
-   分布式系统中的中心节点状态等。

在并发模型中，不同的资源共享与访问方式导致了不同的同步需求：

| 资源类型       | 并发风险           | 处理策略             |
| ---------- | -------------- | ---------------- |
| **不可变资源**  | 无共享写 → 无并发问题   | 可放心并发访问（如常量、纯函数） |
| **独占可变资源** | 必须序列访问 → 串行化执行 | 采用锁、消息队列等串行机制    |
| **共享可变资源** | 高并发访问 → 同步复杂   | 需使用锁、事务、原子操作等    |

---

### 并行性：**同时利用多个计算资源以提升吞吐量**

并行强调的是\*\*“任务在时间上真正重叠地执行”**，通常借助多核 CPU、GPU、分布式节点等硬件资源来**提高性能和吞吐量\*\*。

例如：
-   多核 CPU 上多个线程同时执行；
-   GPU 中千级核心并发执行张量计算；
-   分布式系统中多个节点同时处理用户请求。

**并行性属于资源利用层面的问题**，其目标是**最大化硬件资源的使用率**，以缩短任务完成时间或提升系统吞吐量。

---

### 并发 ≠ 并行，但它们可以重叠

-   **并发是问题域（Concurrency is about dealing with lots of things at once）**：你有多个任务要处理，它们可能竞争资源。
    
-   **并行是解决方式之一（Parallelism is about doing lots of things at once）**：你有多个资源可以同时使用。
    

二者的关系可以用下图概括：

```markdown
┌────────────┐
         │   并发性   │ ← 问题：如何协调共享资源
         └────┬───────┘
              │
         可用并行资源
              ↓
         ┌────────────┐
         │   并行性   │ ← 手段：提高处理效率
         └────────────┘
```

---

### 并发设计

#### ✅ “平凡”并发（Trivial Concurrency）：

-   特征：完全不共享资源。 名义上并行，但**时间上并不重叠**。
-   优点：**安全**。
-   缺点：**资源利用率不高**。
    

#### ✅ “可扩展”并发（Scalable Concurrency）：

-   特征：**真正同时**访问**共享可变资源**。
-   示例：每秒处理百万请求的高并发系统，如 Redis、RabbitMQ。
-   优点：高性能、高吞吐量。
-   难点：**高效但难以保证安全性**并且复杂
	-   解决：需设计高效的同步机制（如 CAS、自旋锁、事务等）以避免竞争和死锁。
    

---

### 总结

| 概念  | 关注点     | 本质问题           | 工程挑战            |
| --- | ------- | -------------- | --------------- |
| 并发性 | 正确性、协调性 | 多任务对共享资源的调度    | 状态同步、线程安全、死锁规避等 |
| 并行性 | 性能、吞吐量  | 多个任务在多个资源上同时执行 | 资源分配、负载均衡、调度策略等 |

并发性是结构，决定你\*\*“能不能做对”**；并行性是能力，决定你**“能不能做快”\*\*。优秀的系统设计往往要求两者兼顾：既能正确协调资源，又能高效利用资源。

---